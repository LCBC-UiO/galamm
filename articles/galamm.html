<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="galamm">
<title>Introduction • galamm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
<meta property="og:description" content="galamm">
<meta property="og:image" content="https://lcbc-uio.github.io/galamm/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">galamm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/galamm.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/lmm_factor.html">Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/glmm_factor.html">Generalized Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/lmm_heteroscedastic.html">Heteroscedastic Linear Mixed Models</a>
    <a class="dropdown-item" href="../articles/mixed_response.html">Models with Mixed Response Types</a>
    <a class="dropdown-item" href="../articles/semiparametric.html">Semiparametric Latent Variable Modeling</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced topics</h6>
    <a class="dropdown-item" href="../articles/optimization.html">Optimization</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/LCBC-UiO/galamm/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/LCBC-UiO/galamm/blob/HEAD/vignettes/galamm.Rmd" class="external-link"><code>vignettes/galamm.Rmd</code></a></small>
      <div class="d-none name"><code>galamm.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/LCBC-UiO/galamm" class="external-link">galamm</a></span><span class="op">)</span></span></code></pre></div>
<p>This vignette is aimed to give you a high-level overview of the types
of models supported by the galamm package, and to point you to relevant
vignettes where you can find more information.</p>
<div class="section level3">
<h3 id="generalized-additive-latent-and-mixed-models">Generalized Additive Latent and Mixed Models<a class="anchor" aria-label="anchor" href="#generalized-additive-latent-and-mixed-models"></a>
</h3>
<p>Generalized additive latent and mixed models (GALAMMs) <span class="citation">(<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">Sørensen, Fjell, and Walhovd 2023</a>)</span> is an
extension of generalized linear latent and mixed models (GLLAMMs) <span class="citation">(<a href="#ref-rabe-heskethGeneralizedMultilevelStructural2004" role="doc-biblioref">Rabe-Hesketh, Skrondal, and Pickles 2004</a>; <a href="#ref-skrondalGeneralizedLatentVariable2004" role="doc-biblioref">Skrondal and Rabe-Hesketh 2004</a>)</span> which
allows both observed responses and latent variables to depend smoothly
on observed variables. <em>Smoothly</em> here means that the
relationship is not assumed to follow a particular parametric form,
e.g., as specified by a linear model. Instead, an <em>a priori</em>
assumption is made that the relationship is smooth, and the model then
attempts to learn the relationship from the data. GALAMM uses smoothing
splines to obtain this, identically to how generalized additive models
(GAMs) <span class="citation">(<a href="#ref-woodGeneralizedAdditiveModels2017a" role="doc-biblioref">Wood
2017</a>)</span> are estimated.</p>
<p>The GLLAMM framework contains many elements which are currently not
implemented in the galamm package. This includes both nonparametric
random effects and a large number of model families, e.g., for censored
responses. If you need any of this, but not semiparametric estimation,
the Stata based <a href="http://www.gllamm.org/" class="external-link">GLLAMM package</a> is
likely the place you should go. Conversely, galamm incorporates crossed
random effects easily and efficiently, while these are hard to specify
using GLLAMM.</p>
<div class="section level4">
<h4 id="response-model">Response Model<a class="anchor" aria-label="anchor" href="#response-model"></a>
</h4>
<p>GALAMMs are specified using three building blocks. First, <span class="math inline">\(n\)</span> responses <span class="math inline">\(y_{1}, \dots, y_{n}\)</span> are assumed
independently distributed according to an exponential family with
density</p>
<p><span class="math display">\[
f\left(y | \theta, \phi\right) = \exp \left( \frac{y\theta(\mu) -
b\left(\theta(\mu)\right)}{\phi} + c\left(y, \phi\right) \right)
\]</span></p>
<p>here <span class="math inline">\(\mu = g^{-1}(\nu)\)</span> is the
mean, <span class="math inline">\(g^{-1}(\cdot)\)</span> is the inverse
of link function <span class="math inline">\(g(\cdot)\)</span>, <span class="math inline">\(\nu\)</span> is a “nonlinear predictor”, <span class="math inline">\(\phi\)</span> is a dispersion parameter, and <span class="math inline">\(b(\cdot)\)</span> and <span class="math inline">\(c(\cdot)\)</span> are known functions. In contrast
to what is assumed, e.g., by <a href="https://cran.r-project.org/package=lme4" class="external-link">lme4</a> <span class="citation">(<a href="#ref-batesFittingLinearMixedEffects2015" role="doc-biblioref">Bates et al. 2015</a>)</span>, the functions <span class="math inline">\(b(\cdot)\)</span>, <span class="math inline">\(c(\cdot)\)</span>, and <span class="math inline">\(g(\cdot)\)</span> are allowed to vary between
observations. That is, the observations can come from different members
of the exponential family. The vignette on <a href="https://lcbc-uio.github.io/galamm/articles/mixed_response.html">models
with mixed response types</a> describes this in detail.</p>
<p>Using canonical link functions, the response model simplifies to</p>
<p><span class="math display">\[
f\left(y | \nu, \phi\right) = \exp \left( \frac{y\nu -
b\left(\nu\right)}{\phi} + c\left(y, \phi\right) \right)
\]</span></p>
</div>
<div class="section level4">
<h4 id="nonlinear-predictor">Nonlinear Predictor<a class="anchor" aria-label="anchor" href="#nonlinear-predictor"></a>
</h4>
<p>Next, the nonlinear predictor, which corresponds to the measurement
model in a classical structural equation model, is defined by</p>
<p><span class="math display">\[
\nu = \sum_{s=1}^{S} f_{s}\left(\mathbf{x}\right) +
\sum_{l=2}^{L}\sum_{m=1}^{M_{l}} \eta_{m}^{(l)}
\mathbf{z}^{(l)}_{m}{}^{'}\boldsymbol{\lambda}_{m}^{(l)},
\]</span></p>
<p>where <span class="math inline">\(\mathbf{x}\)</span> are explanatory
variables, <span class="math inline">\(f_{s}(\mathbf{x})\)</span>, <span class="math inline">\(s=1,\dots,S\)</span> are smooth functions, <span class="math inline">\(\eta_{m}^{(l)}\)</span> are latent variables
varying at level <span class="math inline">\(l\)</span>, and <span class="math inline">\(\boldsymbol{\lambda}_{m}^{(l)}{}^{T}
\mathbf{z}_{m}^{(l)}\)</span> is the weighted sum of a vector of
explanatory variables <span class="math inline">\(\mathbf{z}_{m}^{(l)}\)</span> varying at level
<span class="math inline">\(l\)</span> and parameters <span class="math inline">\(\boldsymbol{\lambda}_{m}^{(l)}\)</span>. Let</p>
<p><span class="math display">\[\boldsymbol{\eta}^{(l)} =
[\eta_{1}^{(l)}, \dots, \eta_{M_{l}}^{(l)}]^{T} \in
\mathbb{R}^{M_{l}}\]</span></p>
<p>be the vector of all latent variables at level <span class="math inline">\(l\)</span>, and</p>
<p><span class="math display">\[\boldsymbol{\eta} =
[\boldsymbol{\eta}^{(2)}, \dots, \boldsymbol{\eta}^{(L)}]^{T} \in
\mathbb{R}^{M}\]</span></p>
<p>the vector of all latent variables belonging to a given level-2 unit,
where <span class="math inline">\(M = \sum_{l=2}^{L} M_{l}\)</span>. The
word “level” is here used to denote a grouping level; they are not
necessarily hierarchical.</p>
</div>
</div>
<div class="section level3">
<h3 id="structural-model">Structural Model<a class="anchor" aria-label="anchor" href="#structural-model"></a>
</h3>
<p>The structural model specifies how the latent variables are related
to each other and to observed variables, and is given by</p>
<p><span class="math display">\[
\boldsymbol{\eta} = \mathbf{B}\boldsymbol{\eta} +
\mathbf{h}\left(\mathbf{w}\right)
+ \boldsymbol{\zeta}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{B}\)</span> is an <span class="math inline">\(M \times M\)</span> matrix of regression
coefficients for regression among latent variables and <span class="math inline">\(\mathbf{w} \in \mathbb{R}^{Q}\)</span> is a vector
of <span class="math inline">\(Q\)</span> predictors for the latent
variables. <span class="math inline">\(\mathbf{h}(\mathbf{w}) =
[\mathbf{h}_{2}(\mathbf{w}), \dots, \mathbf{h}_{L}(\mathbf{w})] \in
\mathbb{R}^{M}\)</span> is a vector of smooth functions whose components
<span class="math inline">\(\mathbf{h}_{l}(\mathbf{w}) \in
\mathbb{R}^{M_{l}}\)</span> are vectors of functions predicting the
latent variables varying at level <span class="math inline">\(l\)</span>, and depending on a subset of the
elements <span class="math inline">\(\mathbf{w}\)</span>. <span class="math inline">\(\boldsymbol{\zeta}\)</span> is a vector of
normally distributed random effects, <span class="math inline">\(\boldsymbol{\zeta}^{(l)} \sim N(\mathbf{0},
\boldsymbol{\Psi}^{(l)})\)</span> for <span class="math inline">\(l=2,\dots,L\)</span>, where <span class="math inline">\(\boldsymbol{\Psi}^{(l)} \in \mathbb{R}^{M_{l}
\times M_{l}}\)</span> is the covariance matrix of random effects at
level <span class="math inline">\(l\)</span>. Defining the <span class="math inline">\(M \times M\)</span> covariance matrix <span class="math inline">\(\boldsymbol{\Psi} =
\text{diag}(\boldsymbol{\Psi}^{(2)}, \dots,
\boldsymbol{\Psi}^{(L)})\)</span>, we also have <span class="math inline">\(\boldsymbol{\zeta} \sim N(\mathbf{0},
\boldsymbol{\Psi})\)</span>.</p>
</div>
<div class="section level3">
<h3 id="mixed-model-representation">Mixed Model Representation<a class="anchor" aria-label="anchor" href="#mixed-model-representation"></a>
</h3>
<p>In <span class="citation">Sørensen, Fjell, and Walhovd (<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">2023</a>)</span> we show that any model specified
as above can be transformed to a GLLAMM, which is essentially a
generalized nonlinear mixed model. This transformation is rather
complex, so we won’t spell it out here, but the key steps are:</p>
<ol style="list-style-type: decimal">
<li>Converting smooth terms to their mixed model form.</li>
<li>Estimate the resulting GLLAMM.</li>
<li>Convert back to the original parametrization.</li>
</ol>
<p>In galamm we use the same transformations as the <a href="https://CRAN.R-project.org/package=gamm4" class="external-link">gamm4</a> package
does.</p>
</div>
<div class="section level3">
<h3 id="maximum-marginal-likelihood-estimation">Maximum Marginal Likelihood Estimation<a class="anchor" aria-label="anchor" href="#maximum-marginal-likelihood-estimation"></a>
</h3>
<p>In mixed model representation, the nonlinear predictor can be written
on the form</p>
<p><span class="math display">\[
\boldsymbol{\nu} = \mathbf{X}(\boldsymbol{\lambda}, \mathbf{B})
\boldsymbol{\beta} +  \mathbf{Z}(\boldsymbol{\lambda}, \mathbf{B})
\boldsymbol{\zeta}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{X}(\boldsymbol{\lambda},
\mathbf{B})\)</span> is the regression matrix for fixed effects <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\mathbf{Z}(\boldsymbol{\lambda},
\mathbf{B})\)</span> is the regression matrix for random effects <span class="math inline">\(\boldsymbol{\zeta}\)</span>. In contrast to with
generalized linear mixed models, however, both matrices will in general
depend on factor loadings <span class="math inline">\(\boldsymbol{\lambda}\)</span> and regression
coefficients between latent variables <span class="math inline">\(\mathbf{B}\)</span>. Both of these are parameters
that need to be estimated, and hence <span class="math inline">\(\mathbf{X}(\boldsymbol{\lambda},
\mathbf{B})\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\mathbf{Z}(\boldsymbol{\lambda},
\mathbf{B})\)</span> need to be updated throughout the estimation
process.</p>
<div class="section level4">
<h4 id="evaluating-the-marginal-likelihood">Evaluating the Marginal Likelihood<a class="anchor" aria-label="anchor" href="#evaluating-the-marginal-likelihood"></a>
</h4>
<p>Plugging the nonlinear predictor into the structural model, we obtain
the joint likelihood for the model. We then obtain the marginal
likelihood by integrating over the random effects, yielding a marginal
likelihood function of the form</p>
<p><span class="math display">\[
L\left(\boldsymbol{\beta}, \boldsymbol{\Lambda}, \boldsymbol{\Gamma},
\boldsymbol{\lambda}, \mathbf{B}, \boldsymbol{\phi}\right) =  \left(2
\pi \phi_{1}\right)^{-r/2}  \int_{\mathbb{R}^{r}} \exp\left(
g\left(\boldsymbol{\beta}, \boldsymbol{\Lambda}, \boldsymbol{\Gamma},
\boldsymbol{\lambda}, \mathbf{B}, \boldsymbol{\phi}, \mathbf{u}\right)
\right) \text{d} \mathbf{u}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{u}\)</span> is a
standardized version of <span class="math inline">\(\boldsymbol{\zeta}\)</span>. In order to evaluate
the marginal likelihood at a given set of parameter values, we use the
Laplace approximation combined with sparse matrix operations, extending
<span class="citation">Bates et al. (<a href="#ref-batesFittingLinearMixedEffects2015" role="doc-biblioref">2015</a>)</span>’s algorithm for linear mixed
models.</p>
</div>
<div class="section level4">
<h4 id="maximizing-the-marginal-likelihood">Maximizing the Marginal Likelihood<a class="anchor" aria-label="anchor" href="#maximizing-the-marginal-likelihood"></a>
</h4>
<p>We obtain maximum marginal likelihood estimates by maximizing <span class="math inline">\(L\left(\boldsymbol{\beta}, \boldsymbol{\Lambda},
\boldsymbol{\Gamma}, \boldsymbol{\lambda}, \mathbf{B},
\boldsymbol{\phi}\right)\)</span>, subject to possible constraints,
e.g., that variances are non-negative. For this, we use the L-BFGS-B
algorithm implement in <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">stats::optim</a></code>. The predicted values
of random effects, <span class="math inline">\(\widehat{\mathbf{u}}\)</span> are obtained as
posterior modes at the final estimates.</p>
</div>
</div>
<div class="section level3">
<h3 id="example-models">Example Models<a class="anchor" aria-label="anchor" href="#example-models"></a>
</h3>
<p>To see how galamm is used in practice, take a look at the vignettes
describing models with different components.</p>
<ul>
<li>
<a href="https://lcbc-uio.github.io/galamm/articles/lmm_factor.html">Linear
mixed models with factor structures</a>.</li>
<li>
<a href="https://lcbc-uio.github.io/galamm/articles/glmm_factor.html">Generalized
linear mixed models with factor structures</a>.</li>
<li>
<a href="https://lcbc-uio.github.io/galamm/articles/lmm_heteroscedastic.html">Linear
mixed models with heteroscedastic residuals</a>.</li>
<li>
<a href="https://lcbc-uio.github.io/galamm/articles/mixed_response.html">Mixed
models with mixed response types</a>.</li>
<li>
<a href="https://lcbc-uio.github.io/galamm/articles/semiparametric.html">Generalized
additive mixed models with factor structures</a>.</li>
</ul>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-batesFittingLinearMixedEffects2015" class="csl-entry">
Bates, Douglas M, Martin Mächler, Ben Bolker, and Steve Walker. 2015.
<span>“Fitting <span>Linear Mixed-Effects Models Using</span>
Lme4.”</span> <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01" class="external-link">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-rabe-heskethGeneralizedMultilevelStructural2004" class="csl-entry">
Rabe-Hesketh, Sophia, Anders Skrondal, and Andrew Pickles. 2004.
<span>“Generalized Multilevel Structural Equation Modeling.”</span>
<em>Psychometrika</em> 69 (2): 167–90. <a href="https://doi.org/10.1007/BF02295939" class="external-link">https://doi.org/10.1007/BF02295939</a>.
</div>
<div id="ref-skrondalGeneralizedLatentVariable2004" class="csl-entry">
Skrondal, Anders, and Sophia Rabe-Hesketh. 2004. <em>Generalized Latent
Variable Modeling</em>. Interdisciplinary <span>Statistics
Series</span>. <span>Boca Raton, Florida</span>: <span>Chapman and
Hall/CRC</span>.
</div>
<div id="ref-sorensenLongitudinalModelingAgeDependent2023" class="csl-entry">
Sørensen, Øystein, Anders M. Fjell, and Kristine B. Walhovd. 2023.
<span>“Longitudinal <span>Modeling</span> of <span>Age-Dependent Latent
Traits</span> with <span>Generalized Additive Latent</span> and
<span>Mixed Models</span>.”</span> <em>Psychometrika</em> 88 (2):
456–86. <a href="https://doi.org/10.1007/s11336-023-09910-z" class="external-link">https://doi.org/10.1007/s11336-023-09910-z</a>.
</div>
<div id="ref-woodGeneralizedAdditiveModels2017a" class="csl-entry">
Wood, Simon N. 2017. <em>Generalized Additive Models: <span>An</span>
Introduction with <span>R</span></em>. 2nd ed. <span>Chapman and
Hall/CRC</span>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Øystein Sørensen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
