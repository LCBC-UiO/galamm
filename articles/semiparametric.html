<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="galamm">
<title>Semiparametric Latent Variable Modeling • galamm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semiparametric Latent Variable Modeling">
<meta property="og:description" content="galamm">
<meta property="og:image" content="https://lcbc-uio.github.io/galamm/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">galamm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/galamm.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/lmm_factor.html">Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/glmm_factor.html">Generalized Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/lmm_heteroscedastic.html">Heteroscedastic Linear Mixed Models</a>
    <a class="dropdown-item" href="../articles/latent_observed_interaction.html">Interactions Between Latent and Observed Covariates</a>
    <a class="dropdown-item" href="../articles/mixed_response.html">Models with Mixed Response Types</a>
    <a class="dropdown-item" href="../articles/semiparametric.html">Semiparametric Latent Variable Modeling</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced topics</h6>
    <a class="dropdown-item" href="../articles/optimization.html">Optimization</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/LCBC-UiO/galamm/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Semiparametric Latent Variable Modeling</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/LCBC-UiO/galamm/blob/HEAD/vignettes/semiparametric.Rmd" class="external-link"><code>vignettes/semiparametric.Rmd</code></a></small>
      <div class="d-none name"><code>semiparametric.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/LCBC-UiO/galamm" class="external-link">galamm</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">gamm4</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme_get.html" class="external-link">theme_set</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>This vignette describes how to use <code>galamm</code> to estimate
latent variable models with smooth terms, or equivalently, generalized
additive mixed models with factor structures. The examples are based on
Section 4 and 5 in <span class="citation">Sørensen, Fjell, and Walhovd
(<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">2023</a>)</span>, but as we cannot share the data,
we have instead simulated somewhat simpler datasets that will be used.
We will gradually add complexity, starting with a simple generalized
additive mixed model. Please refer to the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a> for an overview of the statistical models.</p>
<div class="section level3">
<h3 id="generalized-additive-mixed-models">Generalized Additive Mixed Models<a class="anchor" aria-label="anchor" href="#generalized-additive-mixed-models"></a>
</h3>
<p>We start by showing how <code>galamm</code> can be used to estimated
generalized additive mixed models.</p>
<div class="section level4">
<h4 id="gaussian-responses">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses"></a>
</h4>
<p>The <code>cognition</code> dataset contains simulated data with
measurements of abilities in three cognitive domains.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">cognition</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>For this first example, we focus only on the first item measured for
the first domain.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"11"</span><span class="op">)</span></span></code></pre></div>
<p>Each subject in this dataset has been measured eight times, and we
can plot the measurements as follows:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, group <span class="op">=</span> <span class="va">id</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">.3</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-spaghetti-plot-1.png" alt=""><p class="caption">Plot of data for domain 1 and item 11.</p>
</div>
<p>We use a generalized additive mixed model with random intercepts per
subject to estimate the function relating <span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span>. In terms of the model framework
outlined in the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a>, we model the <span class="math inline">\(i\)</span>th
response from the <span class="math inline">\(j\)</span>th subject
with</p>
<p><span class="math display">\[
y_{ij} = f(x_{ij}) + \eta_{j} + \epsilon_{ij}
\]</span></p>
<p>where <span class="math inline">\(f(x_{ij})\)</span> is a smooth
function to be estimated, <span class="math inline">\(\eta_{j} \sim N(0,
\psi)\)</span> is a random intercept, and <span class="math inline">\(\epsilon_{ij} \sim N(0, \phi)\)</span> is a
residual term.</p>
<p>This model can be estimated using <code>gamm4</code> as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, REML <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in gamm4(y ~ s(x), random = ~(1 | id), data = dat, REML = FALSE): unused argument (REML = FALSE)</span></span></code></pre></div>
<p>The package <code>gamm4</code> uses <code>lme4</code> to fit the
underlying model, and the resulting model has two components.
<code>mod_gamm4$mer</code> contains the mixed model representation,
whereas in <code>mod_gamm4$gam</code> the fixed and random effects
corresponding to spline coefficients have been converted into single
smooth terms. We can look at the model summary for each:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    975.7     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2547  0.0786  0.1946  0.4248  0.8213 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2306   0.4802  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9694   0.9846  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; X(Intercept)   2.8115     0.2034  13.824  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Xs(x)Fx1      -1.4110     0.4242  -3.326  0.00088 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 -0.440</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: binomial </span></span>
<span><span class="co">#&gt; Link function: logit </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   2.8115     0.1662   16.91   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;       edf Ref.df Chi.sq p-value    </span></span>
<span><span class="co">#&gt; s(x) 2.14   2.14  113.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.116   </span></span>
<span><span class="co">#&gt; glmer.ML = 908.96  Scale est. = 1         n = 1600</span></span></code></pre></div>
<p>We can also plot the estimated smooth term:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm4-smooth-1.png" alt=""><p class="caption">Smooth term estimated by gamm4.</p>
</div>
<p>In contrast, invoking the <code>plot</code> function on the mixed
model part gives us a diagnostic plot.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm4-diagnostic-1.png" alt=""><p class="caption">Diagnostic plot for gamm4 model.</p>
</div>
<p>With <code>galamm</code> we use similar argument, but the
<code>random</code> specification is now part of the model formula.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span></span></code></pre></div>
<p>As opposed to <code>gamm4</code>, <code>galamm</code> gives a single
summary. As can be seen, smooth terms are both reported as random
effects, and in a separate line under the header “Approximate
significance of smooth terms:”. Reassuringly, the results from fitting
the model with <code>gamm4</code> and with <code>galamm</code> are
essentially equally, even though they use somewhat different
computational algorithms.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3025.2   3052.1  -1507.6   3015.2     1595 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.93755 -0.65215  0.00612  0.62654  3.14290 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id       (Intercept) 0.8551   0.9247  </span></span>
<span><span class="co">#&gt;  Xr       s(x)        2.0346   1.4264  </span></span>
<span><span class="co">#&gt;  Residual             0.2501   0.5001  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)   1.2694    0.06657 19.0672 4.731e-81</span></span>
<span><span class="co">#&gt; s(x)Fx1      -0.1582    0.20236 -0.7818 4.343e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df     F p-value</span></span>
<span><span class="co">#&gt; s(x) 6.681  6.681 324.9  &lt;2e-16</span></span></code></pre></div>
<p>The <code>plot</code> function now gives us a diagnostic plot, which
by inspection can be seen to be almost identical to the plot produced
from the mixed model part of the <code>gamm4</code> model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-diagnostic-1.png" alt=""><p class="caption">Diagnostic plot for model fitted with galamm.</p>
</div>
<p>In order to plot the smooth term, we use
<code>plot_smooth</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth1-1.png" alt=""><p class="caption">Smooth term estimated with galamm.</p>
</div>
<p>The <code>plot_smooth</code> function is a thin wrapper around the
<code>plot.gam</code> function provided by the <code>mgcv</code> package
<span class="citation">(<a href="#ref-woodGeneralizedAdditiveModels2017a" role="doc-biblioref">Wood
2017</a>)</span>. This means that the arguments used by
<code>plot.gam</code> can be used also here, as see with the examples
below:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>,</span>
<span>  shade <span class="op">=</span> <span class="cn">TRUE</span>, rug <span class="op">=</span> <span class="cn">FALSE</span>, seWithMean <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  shift <span class="op">=</span> <span class="op">+</span><span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth2-1.png" alt=""><p class="caption">Alternative ways of visualizing the smooth term.</p>
</div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth2-2.png" alt=""><p class="caption">Alternative ways of visualizing the smooth term.</p>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses"></a>
</h4>
<p>In the cognition dataset, the responses relating to domain 2 are
binomially distributed. We will use the first trial to illustrate how
such data can be modeled.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"21"</span><span class="op">)</span></span></code></pre></div>
<p>Again we can fit this model using <code>gamm4</code>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>  random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in gamm4(y ~ s(x), random = ~(1 | id), data = dat, family = binomial): unused argument (family = binomial)</span></span></code></pre></div>
<p>We can look at the summary output as before.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    975.7     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2547  0.0786  0.1946  0.4248  0.8213 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2306   0.4802  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9694   0.9846  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; X(Intercept)   2.8115     0.2034  13.824  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Xs(x)Fx1      -1.4110     0.4242  -3.326  0.00088 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 -0.440</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: binomial </span></span>
<span><span class="co">#&gt; Link function: logit </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   2.8115     0.1662   16.91   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;       edf Ref.df Chi.sq p-value    </span></span>
<span><span class="co">#&gt; s(x) 2.14   2.14  113.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.116   </span></span>
<span><span class="co">#&gt; glmer.ML = 908.96  Scale est. = 1         n = 1600</span></span></code></pre></div>
<p>And we can plot the smooth term. The diagnostic plot is not very
useful in the binomial case, so we omit it.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gamm4-binomial-1.png" alt=""><p class="caption">Smooth term estimated by gamm4.</p>
</div>
<p>Again the <code>galamm</code> syntax is similar, but it puts the
random effect specification into the model formula.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span></code></pre></div>
<p>The estimates are very similar, although not identical. The
difference in deviance is due to differences in the way deviance is
defined. The call <code>deviance(mod_gamm4$mer)</code> gives the same
value as in the summary for the model fitted with galamm.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    908.8     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2237  0.0792  0.1947  0.4245  0.8226 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2316   0.4813  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9387   0.9688  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)    2.808     0.1956  14.354 9.989e-47</span></span>
<span><span class="co">#&gt; s(x)Fx1       -1.406     0.4134  -3.402 6.697e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x) 2.124  2.124    114  &lt;2e-16</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gamm-binomial-1.png" alt=""><p class="caption">Smooth term estimated with galamm.</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="generalized-additive-models-with-factor-structures">Generalized Additive Models with Factor Structures<a class="anchor" aria-label="anchor" href="#generalized-additive-models-with-factor-structures"></a>
</h3>
<p>We now add factor structures to the GAMMs. These are the types of
models that neither <code>gamm4</code> nor <code>mgcv</code> are able to
estimate (at least without lots of manual hacking), and where
<code>galamm</code> provides new functionality.</p>
<div class="section level4">
<h4 id="gaussian-responses-1">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses-1"></a>
</h4>
<p>To illustrate basic usage, we continue with the cognition data, but
now use all items of cognitive domain 1. These are all conditionally
normal distributed.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>We now need a factor model to associate the underlying latent trait
<span class="math inline">\(\eta\)</span> with the measurements <span class="math inline">\(y_{i}\)</span>:</p>
<p><span class="math display">\[
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
\]</span></p>
<p>In the structural model, we have a smooth term for the relationship
between the latent trait and x, and we have random intercepts for a
given timepoint within subject <span class="math inline">\(\zeta^{(2)}\)</span>, and for a given subject
across timepoints <span class="math inline">\(\zeta^{(3)}\)</span>.</p>
<p><span class="math display">\[
\eta = h(x) + \zeta^{(2)} + \zeta^{(3)}.
\]</span></p>
<p>The reduced form of the model is</p>
<p><span class="math display">\[
y_{i} = \beta_{i} + \lambda_{i} \left\{ h(x) + \zeta^{(2)} + \zeta^{(3)}
\right\} + \epsilon_{i}
\]</span></p>
<p>We will use a varying-coefficient term, where <span class="math inline">\(h(x)\)</span> is being interpreted as a regression
coefficient for the effect of <span class="math inline">\(\lambda_{i}\)</span> on <span class="math inline">\(y_{i}\)</span>, and the regression term varies
with <span class="math inline">\(x\)</span>. In contrast to <span class="citation">Hastie and Tibshirani (<a href="#ref-hastieVaryingCoefficientModels1993" role="doc-biblioref">1993</a>)</span> and other uses of
varying-coefficient terms, however, in this case the predictor <span class="math inline">\(\lambda_{i}\)</span> is a model parameter. We have
three items loading in <span class="math inline">\(\eta\)</span> and fix
the first loading to 1 for identifiability, so the loading matrix is as
follows:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">loading_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1]</span></span>
<span><span class="co">#&gt; [1,]    1</span></span>
<span><span class="co">#&gt; [2,]   NA</span></span>
<span><span class="co">#&gt; [3,]   NA</span></span></code></pre></div>
<p>We provide thin wrappers around the <code><a href="../reference/sl.html">s()</a></code> and
<code><a href="../reference/t2l.html">t2()</a></code> functions from <code>mgcv</code> to support factor
loadings in smooth terms. The wrappers are named <code><a href="../reference/sl.html">sl()</a></code> and
<code><a href="../reference/t2l.html">t2l()</a></code> to avoid namespace conflicts with <code>mgcv</code>
and <code>gamm4</code>, and the last letter “l” stands for “loading”. In
this example, we set <code>load.var = "item"</code> to specify that the
loadings to be applied are identified by the “item” variable. Using
<code>mgcv</code>’s <code>by</code> variable would also work in this
particular case, i.e., replacing
<code>sl(x, load.var = "loading")</code> with
<code>s(x, by = loading)</code>. However, in most cases this would lead
to identifiability issues due to the way varying-coefficient terms are
set up by <code>mgcv</code>, so <code>galamm</code> provides an
additional <code>load.var</code> arguments which alleviates most of
these issues.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, load.var <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">loading_matrix</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"loading"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We print the model summary below. In the data simulation, the factor
loadings were set to 1, 1.4, and 0.3, respectively, and this is very
well recovered. Furthermore, the ground truth standard deviation at the
<code>id</code> level was 1, at the <code>timepoint</code> level it was
0.5, and the residual standard deviation was 0.1. The estimates are
close to these values. Real data will typically not have this strong
signal, but based on these results, there are no clear indications that
the model is implemented incorrectly.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, load.var = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   -918.2   -853.4    469.1   -938.2     4790 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt;  -2.76   6.46  13.58  23.31  35.84 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading       SE</span></span>
<span><span class="co">#&gt; lambda1  1.0000        .</span></span>
<span><span class="co">#&gt; lambda2  1.3973 0.003531</span></span>
<span><span class="co">#&gt; lambda3  0.3009 0.002146</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.236886 0.48671 </span></span>
<span><span class="co">#&gt;  id           loading      0.857051 0.92577 </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 2.030613 1.42500 </span></span>
<span><span class="co">#&gt;  Residual                  0.009932 0.09966 </span></span>
<span><span class="co">#&gt; Number of obs: 4800, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; item11            1.2694    0.06663 19.0513 6.412e-81</span></span>
<span><span class="co">#&gt; item12            1.7788    0.09307 19.1128 1.977e-81</span></span>
<span><span class="co">#&gt; item13            0.3797    0.02019 18.8077 6.531e-79</span></span>
<span><span class="co">#&gt; s(x):loadingFx1  -0.1496    0.19977 -0.7488 4.540e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df    F p-value</span></span>
<span><span class="co">#&gt; s(x):loading 8.719  8.719 4469  &lt;2e-16</span></span></code></pre></div>
<p>We also plot the smooth term. Since we had a very large amount of
data, there is essentially no uncertainty about the estimate.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-factor-1.png" alt=""><p class="caption">Smooth term for GAMM with factor structure.</p>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses-1">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses-1"></a>
</h4>
<p>We can now move on to the part of the cognition data that is
conditionally binomially distributed. We consider domain 2, where each
response measures success or not in a single trial. In this case there
are only two items, so we must change the lambda matrix accordingly.
Other than that, and setting <code>family = binomial</code>, the model
is the same as before.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, load.var <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="va">binomial</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"loading"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The summary is shown below. The factor loading <span class="math inline">\(\lambda_{2} = 2\)</span> was used when simulating
the data, and including the uncertainty, our estimate covers the true
value well. Also note that the variation between individuals (group
<code>id</code>) and the variation between timepoints within individuals
(group <code>timepoint:id</code>) gets lumped together at the
<code>id</code> level. The estimated variation at the
<code>timepoint:id</code> level is zero. This is a well-known phenomenon
when fitting mixed models, given book-length treatment in <span class="citation">Hodges (<a href="#ref-hodgesRichlyParameterizedLinear2013" role="doc-biblioref">2013</a>)</span>. In this case, it is likely due to
the fact that we only have two measurements at each timepoint, and also
the fact that we use the Laplace approximation to integrate over the
random effects, and this approximation may be inaccurate for binomial
data with a low number of repeated observations <span class="citation">(<a href="#ref-joeAccuracyLaplaceApproximation2008" role="doc-biblioref">Joe 2008</a>)</span>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, load.var = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   1495.5   1538.0   -740.8   1614.8     3193 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -15.8546   0.0279   0.0780   0.1985   1.3948 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading     SE</span></span>
<span><span class="co">#&gt; lambda1   1.000      .</span></span>
<span><span class="co">#&gt; lambda2   2.202 0.3007</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.0000   0.0000  </span></span>
<span><span class="co">#&gt;  id           loading      0.6222   0.7888  </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 1.5388   1.2405  </span></span>
<span><span class="co">#&gt; Number of obs: 3200, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; item21             2.944     0.1903  15.473 5.249e-54</span></span>
<span><span class="co">#&gt; item22             6.319     0.5853  10.796 3.612e-27</span></span>
<span><span class="co">#&gt; s(x):loadingFx1   -1.389     0.2837  -4.897 9.733e-07</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x):loading 2.491  2.491  115.1  &lt;2e-16</span></span></code></pre></div>
<p>The true value 2 for the factor loading is well within the 95 %
confidence limits.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mod</span>, parm <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></span>
<span><span class="co">#&gt;            2.5 %   97.5 %</span></span>
<span><span class="co">#&gt; lambda1 1.612341 2.791192</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="multivariate-gaussian-model">Multivariate Gaussian Model<a class="anchor" aria-label="anchor" href="#multivariate-gaussian-model"></a>
</h4>
<p>We now do a joint analysis of domain 1 and domain 3, for which all
item responses are conditionally normally distributed.</p>
<p>Letting <span class="math inline">\(\eta_{1}\)</span> denote latent
ability in domain 1 and <span class="math inline">\(\eta_{3}\)</span>
denote latent ability in domain 3, and <span class="math inline">\(\lambda_{i1}\)</span> and <span class="math inline">\(\lambda_{i3}\)</span> be corresponding factor
loadings for the <span class="math inline">\(i\)</span>th item measuring
each domain, the measurement model is now</p>
<p><span class="math display">\[
y_{i} = \beta_{ij} + \lambda_{ij} \eta_{j} + \epsilon_{ij} ~ j=1,3
\]</span></p>
<p>To avoid unnecessary complexity, we assume the residual standard
deviation is the same for all responses. The <a href="https://lcbc-uio.github.io/galamm/articles/lmm_heteroscedastic.html">vignette
on linear mixed models with heteroscedastic residuals</a> shows how this
assumption can be relaxed. The data were also simulated with all
residual standard deviations equal, so in this case the homoscedasticity
assumption is satisfied.</p>
<p>In the structural model, we have a smooth term for the relationship
between the latent trait and x, and we have random intercepts for a
given timepoint within subject <span class="math inline">\(\zeta^{(2)}\)</span>, and for a given subject
across timepoints <span class="math inline">\(\zeta^{(3)}\)</span>.</p>
<p><span class="math display">\[
\eta_{j} = h_{j}(x) + \zeta_{j}^{(2)} + \zeta_{j}^{(3)} ~j=1,3.
\]</span></p>
<p>We first subset the cognition dataset to get the measurements of
domain 1 and 3, which are conditionally normally distributed. We also
create two dummy variable, <code>domain1</code> and
<code>domain3</code>, which we need when defining the formulas
below.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">dat</span>, </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"domain1"</span>, <span class="st">"domain3"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Below is a plot of the data we are analyzing.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, group <span class="op">=</span> <span class="va">id</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">.1</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">.1</span>, alpha <span class="op">=</span> <span class="fl">.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html" class="external-link">facet_wrap</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/vars.html" class="external-link">vars</a></span><span class="op">(</span><span class="va">item</span><span class="op">)</span>, scales <span class="op">=</span> <span class="st">"free_y"</span>,</span>
<span>    labeller <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/as_labeller.html" class="external-link">as_labeller</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"Domain"</span>, <span class="fu"><a href="https://rdrr.io/r/base/substr.html" class="external-link">substr</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, </span>
<span>                                             <span class="st">"item"</span>, <span class="fu"><a href="https://rdrr.io/r/base/substr.html" class="external-link">substr</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>strip.background <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_blank</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>        panel.grid <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_blank</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-multivariate-spaghetti-1.png" alt=""><p class="caption">Spaghetti plot of measurements of domain 1 and 3.</p>
</div>
<p>Mathematically, the factor loading matrix we want is</p>
<p><span class="math display">\[
\Lambda =
\begin{pmatrix}
1 &amp; 0 \\
\lambda_{12} &amp; 0 \\
\lambda_{13} &amp; 0 \\
0 &amp; 1 \\
0 &amp; \lambda_{22} \\
0 &amp; \lambda_{23} \\
0 &amp; \lambda_{24}
\end{pmatrix}
\]</span></p>
<p>In code, that becomes:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>                 <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]   NA    0</span></span>
<span><span class="co">#&gt; [3,]   NA    0</span></span>
<span><span class="co">#&gt; [4,]    0    1</span></span>
<span><span class="co">#&gt; [5,]    0   NA</span></span>
<span><span class="co">#&gt; [6,]    0   NA</span></span>
<span><span class="co">#&gt; [7,]    0   NA</span></span></code></pre></div>
<p>Below is the call to fit the model.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, k <span class="op">=</span> <span class="fl">6</span>, by <span class="op">=</span> <span class="va">domain</span>, load.var <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain3</span><span class="op">:</span><span class="va">ability3</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">|</span> <span class="va">id</span><span class="op">:</span><span class="va">timepoint</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain3</span><span class="op">:</span><span class="va">ability3</span> <span class="op">|</span> <span class="va">id</span><span class="op">:</span><span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Before showing the results, some comments are probably useful. In the
<code>formula</code>, the first term <code>domain</code> represents an
intercept per domain. Ideally we should have had an intercept per item,
representing the item bias, but in this case all item biases were set to
zero when simulating the data, and thus estimating an intercept for all
of them is unnecessary. Next, the term
<code>sl(x, k = 6, by = domain, load.var = c("ability1", "ability3"))</code>
specifies that we want one smooth estimated independently for each level
of the factor variable <code>domain</code>. For the two levels of the
factor variable <code>domain</code>, the loadings <code>ability1</code>
and <code>ability3</code> should be applied, respectively. These
represent the two columns in the loading matrix above. Setting
<code>k = 6</code> specifies that we want six basis functions for each
of the smooth terms. The first random effects term
<code>(0 + domain1:ability1 + domain3:ability3 | id)</code> corresponds
to <span class="math inline">\(\lambda \zeta_{j}^{(3)}\)</span>, and by
specifying them in a single term, we allow the level-3 random intercepts
to be correlated. The next two random effect terms
<code>(0 + domain1:ability1 | id:timepoint)</code> and
<code>(0 + domain3:ability3 | id:timepoint)</code> correspond to <span class="math inline">\(\lambda \zeta_{j}^{(2)}\)</span>, and by
specifying them independently we state that the level-2 random
intercepts should be uncorrelated. The assumption of uncorrelated random
intercepts at level 2 is reasonable here because we simulated the data
this way. If correlations at both levels should be allowed, we could
simply replace all the three random effects terms with the single term
<code>(0 + domain1:ability1 + domain3:ability3 | id / timepoint)</code>.</p>
<p>We can now look at the model output, which shows that the factor
loadings are estimated very close to their true value, and that the
level-3 random intercepts are estimated to have correlation of 0.61
which is actually a reasonable approximation of the true value 0.4,
since random effect correlations are notoriously hard to estimate.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, k = 6, by = domain, load.var = c("ability1",  </span></span>
<span><span class="co">#&gt;     "ability3")) + (0 + domain1:ability1 + domain3:ability3 |  </span></span>
<span><span class="co">#&gt;     id) + (0 + domain1:ability1 | id:timepoint) + (0 + domain3:ability3 |      id:timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;  -1319.6  -1195.1    676.8  -1353.6    11183 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt;  -10.90    5.65 1015.94 1264.17 2490.17 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1       SE ability3        SE</span></span>
<span><span class="co">#&gt; lambda1    1.000        .        .         .</span></span>
<span><span class="co">#&gt; lambda2    1.398 0.002568        .         .</span></span>
<span><span class="co">#&gt; lambda3    0.302 0.002006        .         .</span></span>
<span><span class="co">#&gt; lambda4        .        .   1.0000         .</span></span>
<span><span class="co">#&gt; lambda5        .        .   0.9995 0.0007682</span></span>
<span><span class="co">#&gt; lambda6        .        .   1.0009 0.0007690</span></span>
<span><span class="co">#&gt; lambda7        .        .   2.0003 0.0015716</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups         Name                  Variance Std.Dev. Corr</span></span>
<span><span class="co">#&gt;  id.timepoint   domain3:ability3       0.46249 0.6801       </span></span>
<span><span class="co">#&gt;  id.timepoint.1 domain1:ability1       0.23946 0.4893       </span></span>
<span><span class="co">#&gt;  id             domain1:ability1       8.70515 2.9504       </span></span>
<span><span class="co">#&gt;                 domain3:ability3      18.80099 4.3360   0.61</span></span>
<span><span class="co">#&gt;  Xr.0           s(x):domain3:ability3 13.89382 3.7274       </span></span>
<span><span class="co">#&gt;  Xr             s(x):domain1:ability1 16.36177 4.0450       </span></span>
<span><span class="co">#&gt;  Residual                              0.01007 0.1003       </span></span>
<span><span class="co">#&gt; Number of obs: 11200, groups:  id:timepoint, 1600; id, 200; Xr.0, 4; Xr, 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                           Estimate Std. Error  t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)              -0.003987   0.004679  -0.8522   0.3941</span></span>
<span><span class="co">#&gt; domain3                   0.002019   0.007608   0.2654   0.7907</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1  0.152050   0.118988   1.2779   0.2013</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3Fx1 -9.599527   0.171067 -56.1155   0.0000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df      F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 4.998  4.998   7718  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3 4.996  4.996 101282  &lt;2e-16</span></span></code></pre></div>
<p>We now study the smooth terms. Since in this case we know the true
values, we include these for comparison. First we look at the smooth for
domain 1, and we see that the estimate very well captures the true
value.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># x-values to plot the true function</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, by <span class="op">=</span> <span class="fl">.01</span><span class="op">)</span></span>
<span><span class="co"># True function</span></span>
<span><span class="va">f0</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="va">pi</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="co"># Scale to mean zero across x</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">f0</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu">f0</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot estimate</span></span>
<span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, select <span class="op">=</span> <span class="fl">1</span>, scale <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co"># Overlay true curve in red</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-multivariate-gaussian-smooth1-1.png" alt=""><p class="caption">Comparison of estimate to true value.</p>
</div>
<p>Next we look at domain 3. In this case we see that our estimate is
oversmoothing the true value. This is probably because we the number of
basis functions to only six, to avoid convergence issues. In any case,
the overall shape of the true trajectory is clearly being captured.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># True function</span></span>
<span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fl">0.2</span> <span class="op">*</span> <span class="va">x</span><span class="op">^</span><span class="fl">11</span> <span class="op">*</span> <span class="op">(</span><span class="fl">10</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">6</span> <span class="op">+</span> <span class="fl">10</span> <span class="op">*</span></span>
<span>    <span class="op">(</span><span class="fl">10</span> <span class="op">*</span> <span class="va">x</span><span class="op">)</span><span class="op">^</span><span class="fl">3</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">x</span><span class="op">)</span><span class="op">^</span><span class="fl">10</span></span>
<span><span class="op">}</span></span>
<span><span class="co"># Scale to mean zero across x</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">f2</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu">f2</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot estimate</span></span>
<span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, select <span class="op">=</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co"># Overlay true curve in red</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-multivariate-gaussian-smooth2-1.png" alt=""><p class="caption">Comparison of estimate to true value.</p>
</div>
</div>
<div class="section level4">
<h4 id="multivariate-binomial-and-gaussian-model">Multivariate Binomial and Gaussian Model<a class="anchor" aria-label="anchor" href="#multivariate-binomial-and-gaussian-model"></a>
</h4>
<p>We now extend the model above to also include the items measuring
domain 2, which are all binomially distributed with a single trial.</p>
<p>We start by adding dummy variables for each domain, as before.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">cognition</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">mm</span><span class="op">)</span></span></code></pre></div>
<p>Next we define the factor loading matrix, which now has three
columns.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>,</span>
<span>  ncol <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt;  [1,]    1    0    0</span></span>
<span><span class="co">#&gt;  [2,]   NA    0    0</span></span>
<span><span class="co">#&gt;  [3,]   NA    0    0</span></span>
<span><span class="co">#&gt;  [4,]    0    1    0</span></span>
<span><span class="co">#&gt;  [5,]    0   NA    0</span></span>
<span><span class="co">#&gt;  [6,]    0    0    1</span></span>
<span><span class="co">#&gt;  [7,]    0    0   NA</span></span>
<span><span class="co">#&gt;  [8,]    0    0   NA</span></span>
<span><span class="co">#&gt;  [9,]    0    0   NA</span></span></code></pre></div>
<p>The responses are now either conditionally Gaussian or conditionally
binomial, so we define the family object and family mapping as
follows:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">family</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">gaussian</span>, <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="va">family_mapping</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fl">1L</span>, <span class="fl">2L</span><span class="op">)</span></span></code></pre></div>
<p>Since this model will be computationally challenging, we need to
think about the optimization. We define the control object as follows,
where <code>trace = 3</code> means that we want the <code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">optim()</a></code>
function to be relatively verbose, <code>REPORT = 5</code> which means
that we want it to report every fifth iteration, and
<code>factr = 1e9</code> which means that when the reduction in marginal
loglikelihood is within <span class="math inline">\(10^{9}\)</span>
times machine precision, then convergence has occured. The default for
<code>factr</code> is <code>1e7</code>, so we are less strict than
default. Finally, <code>reduced_hessian = TRUE</code> means that at the
maximum marginal likelihood solution that is found, the Hessian matrix
should only contain partial derivatives with respect to the fixed
regression coefficients and the factor loadings. That is, it should not
contain derivatives with respect to the variance components, which for
models of this complexity typically leads to non-positive definite
Hessian matrices. This also means that Wald type confidence intervals
based on this Hessian matrix are more approximate than usual, since they
ignore the uncertainty in the variance components. However, the
simulations in <span class="citation">Sørensen, Fjell, and Walhovd (<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">2023</a>)</span> suggest that the results
confidence intervals still are quite good for most parameters.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">control</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/galamm_control.html">galamm_control</a></span><span class="op">(</span></span>
<span>  optim_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>trace <span class="op">=</span> <span class="fl">3</span>, REPORT <span class="op">=</span> <span class="fl">5</span>, factr <span class="op">=</span> <span class="fl">1e9</span><span class="op">)</span>,</span>
<span>  reduced_hessian <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>For this example, we also remove the level-2 disturbances, as they
lead to further computational challenges which are not directly relevant
to this example. For real data analysis in the first example of <span class="citation">Sørensen, Fjell, and Walhovd (<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">2023</a>)</span>, level-2 disturbances were
included and the model did converge, so it is not necessary in general
to drop this level.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, k <span class="op">=</span> <span class="fl">6</span>, by <span class="op">=</span> <span class="va">domain</span>, </span>
<span>       load.var <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain2</span><span class="op">:</span><span class="va">ability2</span> <span class="op">+</span> <span class="va">domain3</span><span class="op">:</span><span class="va">ability3</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="va">family</span>,</span>
<span>  family_mapping <span class="op">=</span> <span class="va">family_mapping</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">lmat</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="va">control</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; N = 21, M = 20 machine precision = 2.22045e-16</span></span>
<span><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span><span class="co">#&gt; At iterate     0  f=        25990  |proj g|=         6749</span></span>
<span><span class="co">#&gt; At iterate     5  f =        19398  |proj g|=        780.41</span></span>
<span><span class="co">#&gt; At iterate    10  f =        15323  |proj g|=        1141.7</span></span>
<span><span class="co">#&gt; At iterate    15  f =        14627  |proj g|=        1576.5</span></span>
<span><span class="co">#&gt; At iterate    20  f =        14483  |proj g|=        162.98</span></span>
<span><span class="co">#&gt; At iterate    25  f =        14397  |proj g|=         37.08</span></span>
<span><span class="co">#&gt; At iterate    30  f =        14329  |proj g|=        314.17</span></span>
<span><span class="co">#&gt; At iterate    35  f =        14260  |proj g|=        191.23</span></span>
<span><span class="co">#&gt; At iterate    40  f =        14247  |proj g|=         27.04</span></span>
<span><span class="co">#&gt; At iterate    45  f =        14242  |proj g|=        30.921</span></span>
<span><span class="co">#&gt; At iterate    50  f =        14239  |proj g|=        28.512</span></span>
<span><span class="co">#&gt; At iterate    55  f =        14237  |proj g|=        48.242</span></span>
<span><span class="co">#&gt; At iterate    60  f =        14237  |proj g|=        25.373</span></span>
<span><span class="co">#&gt; At iterate    65  f =        14236  |proj g|=        150.72</span></span>
<span><span class="co">#&gt; At iterate    70  f =        14231  |proj g|=        110.19</span></span>
<span><span class="co">#&gt; At iterate    75  f =        14230  |proj g|=        57.963</span></span>
<span><span class="co">#&gt; At iterate    80  f =        14225  |proj g|=        32.814</span></span>
<span><span class="co">#&gt; At iterate    85  f =        14224  |proj g|=        23.879</span></span>
<span><span class="co">#&gt; At iterate    90  f =        14223  |proj g|=        17.141</span></span>
<span><span class="co">#&gt; At iterate    95  f =        14220  |proj g|=        13.796</span></span>
<span><span class="co">#&gt; At iterate   100  f =        14219  |proj g|=        21.301</span></span>
<span><span class="co">#&gt; final  value 14218.761356 </span></span>
<span><span class="co">#&gt; stopped after 101 iterations</span></span></code></pre></div>
<p>The summary output is shown below:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, k = 6, by = domain, load.var = c("ability1",  </span></span>
<span><span class="co">#&gt;     "ability2", "ability3")) + (0 + domain1:ability1 + domain2:ability2 +      domain3:ability3 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; Control: control</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        AIC        BIC     logLik   deviance   df.resid </span></span>
<span><span class="co">#&gt;    28481.5    28648.2   -14218.8 35771641.8      14378 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -253.327   -2.731    0.058   70.749  133.839 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1      SE ability2    SE ability3       SE</span></span>
<span><span class="co">#&gt; lambda1   1.0000       .        .     .        .        .</span></span>
<span><span class="co">#&gt; lambda2   1.4005 0.01851        .     .        .        .</span></span>
<span><span class="co">#&gt; lambda3   0.2986 0.01512        .     .        .        .</span></span>
<span><span class="co">#&gt; lambda4        .       .    1.000     .        .        .</span></span>
<span><span class="co">#&gt; lambda5        .       .    1.725 0.147        .        .</span></span>
<span><span class="co">#&gt; lambda6        .       .        .     .   1.0000        .</span></span>
<span><span class="co">#&gt; lambda7        .       .        .     .   0.9999 0.005676</span></span>
<span><span class="co">#&gt; lambda8        .       .        .     .   1.0007 0.005679</span></span>
<span><span class="co">#&gt; lambda9        .       .        .     .   2.0111 0.011334</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name                  Variance Std.Dev. Corr     </span></span>
<span><span class="co">#&gt;  id     domain1:ability1        2.452   1.566            </span></span>
<span><span class="co">#&gt;         domain2:ability2        3.646   1.909   0.86     </span></span>
<span><span class="co">#&gt;         domain3:ability3       11.898   3.449   0.82 1.00</span></span>
<span><span class="co">#&gt;  Xr.1   s(x):domain3:ability3 223.339  14.945            </span></span>
<span><span class="co">#&gt;  Xr.0   s(x):domain2:ability2   1.665   1.290            </span></span>
<span><span class="co">#&gt;  Xr     s(x):domain1:ability1   7.465   2.732            </span></span>
<span><span class="co">#&gt; Number of obs: 14400, groups:  id, 200; Xr.1, 4; Xr.0, 4; Xr, 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                           Estimate Std. Error    z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)               0.001827    0.03152    0.05796 9.538e-01</span></span>
<span><span class="co">#&gt; domain2                   0.811792    0.12790    6.34727 2.192e-10</span></span>
<span><span class="co">#&gt; domain3                   0.056704    0.04989    1.13662 2.557e-01</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1  0.159995    0.10127    1.57989 1.141e-01</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2Fx1 -0.337532    0.33719   -1.00103 3.168e-01</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3Fx1 -9.803813    0.08146 -120.35373 0.000e+00</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df       F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 4.937  4.937   639.3  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2 4.659  4.659  1714.5  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3 4.998  4.998 16093.4  &lt;2e-16</span></span></code></pre></div>
<p>The estimated smooth terms are shown in the plots below.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, select <span class="op">=</span> <span class="fl">1</span>, scale <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-mixedresponse-smooths1-1.png" alt=""><p class="caption">First smooth term for semiparametric mixed response
model.</p>
</div>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, select <span class="op">=</span> <span class="fl">2</span>, scale <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-mixedresponse-smooths2-1.png" alt=""><p class="caption">Second smooth term for semiparametric mixed response
model.</p>
</div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, select <span class="op">=</span> <span class="fl">3</span>, scale <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-mixedresponse-smooths3-1.png" alt=""><p class="caption">Third smooth term for semiparametric mixed response
model.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-hastieVaryingCoefficientModels1993" class="csl-entry">
Hastie, Trevor, and Robert Tibshirani. 1993.
<span>“Varying-<span>Coefficient Models</span>.”</span> <em>Journal of
the Royal Statistical Society: Series B (Methodological)</em> 55 (4):
757–79. <a href="https://doi.org/10.1111/j.2517-6161.1993.tb01939.x" class="external-link">https://doi.org/10.1111/j.2517-6161.1993.tb01939.x</a>.
</div>
<div id="ref-hodgesRichlyParameterizedLinear2013" class="csl-entry">
Hodges, James S. 2013. <em>Richly <span>Parameterized Linear Models
Additive</span>, <span>Time Series</span>, and <span>Spatial Models
Using Random Effects</span></em>. 1st ed. Chapman &amp;
<span>Hall</span>/<span>CRC Texts</span> in <span>Statistical
Science</span>. <span>Chapman &amp; Hall</span>.
</div>
<div id="ref-joeAccuracyLaplaceApproximation2008" class="csl-entry">
Joe, Harry. 2008. <span>“Accuracy of <span>Laplace</span> Approximation
for Discrete Response Mixed Models.”</span> <em>Computational Statistics
&amp; Data Analysis</em> 52 (12): 5066–74. <a href="https://doi.org/10.1016/j.csda.2008.05.002" class="external-link">https://doi.org/10.1016/j.csda.2008.05.002</a>.
</div>
<div id="ref-sorensenLongitudinalModelingAgeDependent2023" class="csl-entry">
Sørensen, Øystein, Anders M. Fjell, and Kristine B. Walhovd. 2023.
<span>“Longitudinal <span>Modeling</span> of <span>Age-Dependent Latent
Traits</span> with <span>Generalized Additive Latent</span> and
<span>Mixed Models</span>.”</span> <em>Psychometrika</em> 88 (2):
456–86. <a href="https://doi.org/10.1007/s11336-023-09910-z" class="external-link">https://doi.org/10.1007/s11336-023-09910-z</a>.
</div>
<div id="ref-woodGeneralizedAdditiveModels2017a" class="csl-entry">
Wood, Simon N. 2017. <em>Generalized Additive Models: <span>An</span>
Introduction with <span>R</span></em>. 2nd ed. <span>Chapman and
Hall/CRC</span>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Øystein Sørensen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
