<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Semiparametric Latent Variable Modeling • galamm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semiparametric Latent Variable Modeling">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">galamm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/galamm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/lmm_factor.html">Linear Mixed Models with Factor Structures</a></li>
    <li><a class="dropdown-item" href="../articles/glmm_factor.html">Generalized Linear Mixed Models with Factor Structures</a></li>
    <li><a class="dropdown-item" href="../articles/lmm_heteroscedastic.html">Heteroscedastic Linear Mixed Models</a></li>
    <li><a class="dropdown-item" href="../articles/latent_observed_interaction.html">Interactions Between Latent and Observed Covariates</a></li>
    <li><a class="dropdown-item" href="../articles/mixed_response.html">Models with Mixed Response Types</a></li>
    <li><a class="dropdown-item" href="../articles/semiparametric.html">Semiparametric Latent Variable Modeling</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Advanced topics</h6></li>
    <li><a class="dropdown-item" href="../articles/scaling.html">Computational Scaling</a></li>
    <li><a class="dropdown-item" href="../articles/optimization.html">Optimization</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/LCBC-UiO/galamm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Semiparametric Latent Variable Modeling</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/LCBC-UiO/galamm/blob/main/vignettes/semiparametric.Rmd" class="external-link"><code>vignettes/semiparametric.Rmd</code></a></small>
      <div class="d-none name"><code>semiparametric.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/LCBC-UiO/galamm" class="external-link">galamm</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">gamm4</span><span class="op">)</span></span></code></pre></div>
<p>This vignette describes how to use <code>galamm</code> to estimate
latent variable models with smooth terms, or equivalently, generalized
additive mixed models with factor structures. The examples are based on
Section 4 and 5 in <span class="citation">Sørensen, Fjell, and Walhovd
(<a href="#ref-sorensenLongitudinalModelingAgeDependent2023">2023</a>)</span>,
but as we cannot share the data, we have instead simulated somewhat
simpler datasets that will be used. We will gradually add complexity,
starting with a simple generalized additive mixed model. Please refer to
the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a> for an overview of the statistical models.</p>
<div class="section level3">
<h3 id="generalized-additive-mixed-models">Generalized Additive Mixed Models<a class="anchor" aria-label="anchor" href="#generalized-additive-mixed-models"></a>
</h3>
<p>We start by showing how <code>galamm</code> can be used to estimated
generalized additive mixed models.</p>
<div class="section level4">
<h4 id="gaussian-responses">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses"></a>
</h4>
<p>The <code>cognition</code> dataset contains simulated data with
measurements of abilities in three cognitive domains.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">cognition</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>For this first example, we focus only on the first item measured for
the first domain.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"11"</span><span class="op">)</span></span></code></pre></div>
<p>Each subject in this dataset has been measured eight times, and we
can plot the measurements as follows:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">x</span>, <span class="va">dat</span><span class="op">$</span><span class="va">y</span>, type <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">"x"</span>, ylab <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">id</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">dd</span> <span class="op">&lt;-</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">id</span> <span class="op">==</span> <span class="va">i</span>, <span class="op">]</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">x</span>, <span class="va">dd</span><span class="op">$</span><span class="va">y</span>, col <span class="op">=</span> <span class="st">"gray"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">x</span>, <span class="va">dat</span><span class="op">$</span><span class="va">y</span>, pch <span class="op">=</span> <span class="fl">20</span>, lwd <span class="op">=</span> <span class="fl">.05</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-spaghetti-plot-1.png" alt="Plot of data for domain 1 and item 11."><div class="figcaption">Plot of data for domain 1 and item 11.</div>
</div>
<p>We use a generalized additive mixed model with random intercepts per
subject to estimate the function relating
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
In terms of the model framework outlined in the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a>, we model the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th
response from the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>th
subject with</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>η</mi><mi>j</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">
y_{ij} = f(x_{ij}) + \eta_{j} + \epsilon_{ij}
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_{ij})</annotation></semantics></math>
is a smooth function to be estimated,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>η</mi><mi>j</mi></msub><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>ψ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\eta_{j} \sim N(0, \psi)</annotation></semantics></math>
is a random intercept, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∼</mo><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mi>ϕ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\epsilon_{ij} \sim N(0, \phi)</annotation></semantics></math>
is a residual term.</p>
<p>This model can be estimated using <code>gamm4</code> as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, REML <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>The package <code>gamm4</code> uses <code>lme4</code> to fit the
underlying model, and the resulting model has two components.
<code>mod_gamm4$mer</code> contains the mixed model representation,
whereas in <code>mod_gamm4$gam</code> the fixed and random effects
corresponding to spline coefficients have been converted into single
smooth terms. We can look at the model summary for each:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by maximum likelihood  ['lmerMod']</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3025.2   3052.1  -1507.6   3015.2     1595 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.93755 -0.65215  0.00612  0.62654  3.14289 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id       (Intercept) 0.8551   0.9247  </span></span>
<span><span class="co">#&gt;  Xr       s(x)        2.0341   1.4262  </span></span>
<span><span class="co">#&gt;  Residual             0.2501   0.5001  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error t value</span></span>
<span><span class="co">#&gt; X(Intercept)  1.26938    0.06657  19.067</span></span>
<span><span class="co">#&gt; Xs(x)Fx1     -0.15814    0.20156  -0.785</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  1.26938    0.06657   19.07   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df     F p-value    </span></span>
<span><span class="co">#&gt; s(x) 6.681  6.681 324.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.253   </span></span>
<span><span class="co">#&gt; lmer.REML = 3015.2  Scale est. = 0.25012   n = 1600</span></span></code></pre></div>
<p>We can also plot the estimated smooth term:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm4-smooth-1.png" alt="Smooth term estimated by gamm4."><div class="figcaption">Smooth term estimated by gamm4.</div>
</div>
<p>In contrast, invoking the <code>plot</code> function on the mixed
model part gives us a diagnostic plot.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm4-diagnostic-1.png" alt="Diagnostic plot for gamm4 model."><div class="figcaption">Diagnostic plot for gamm4 model.</div>
</div>
<p>With <code>galamm</code> we use similar argument, but the
<code>random</code> specification is now part of the model formula.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span></span></code></pre></div>
<p>As opposed to <code>gamm4</code>, <code>galamm</code> gives a single
summary. As can be seen, smooth terms are both reported as random
effects, and in a separate line under the header “Approximate
significance of smooth terms:”. Reassuringly, the results from fitting
the model with <code>gamm4</code> and with <code>galamm</code> are
essentially equally, even though they use somewhat different
computational algorithms.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3025.2   3052.1  -1507.6   3015.2     1595 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.93755 -0.65215  0.00612  0.62654  3.14290 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id       (Intercept) 0.8551   0.9247  </span></span>
<span><span class="co">#&gt;  Xr       s(x)        2.0346   1.4264  </span></span>
<span><span class="co">#&gt;  Residual             0.2501   0.5001  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)   1.2694    0.06657 19.0672 4.731e-81</span></span>
<span><span class="co">#&gt; s(x)Fx1      -0.1582    0.20236 -0.7818 4.343e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df     F p-value</span></span>
<span><span class="co">#&gt; s(x) 6.681  6.681 324.9  &lt;2e-16</span></span></code></pre></div>
<p>The <code>plot</code> function now gives us a diagnostic plot, which
by inspection can be seen to be almost identical to the plot produced
from the mixed model part of the <code>gamm4</code> model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm-diagnostic-1.png" alt="Diagnostic plot for model fitted with galamm."><div class="figcaption">Diagnostic plot for model fitted with
galamm.</div>
</div>
<p>In order to plot the smooth term, we use
<code>plot_smooth</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm-smooth1-1.png" alt="Smooth term estimated with galamm."><div class="figcaption">Smooth term estimated with galamm.</div>
</div>
<p>The <code>plot_smooth</code> function is a thin wrapper around the
<code>plot.gam</code> function provided by the <code>mgcv</code> package
<span class="citation">(<a href="#ref-woodGeneralizedAdditiveModels2017">Wood 2017</a>)</span>.
This means that the arguments used by <code>plot.gam</code> can be used
also here, as see with the examples below:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>,</span>
<span>  shade <span class="op">=</span> <span class="cn">TRUE</span>, rug <span class="op">=</span> <span class="cn">FALSE</span>, seWithMean <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  shift <span class="op">=</span> <span class="op">+</span><span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm-smooth2-1.png" alt="Alternative ways of visualizing the smooth term."><div class="figcaption">Alternative ways of visualizing the smooth
term.</div>
</div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-gamm-smooth2-2.png" alt="Alternative ways of visualizing the smooth term."><div class="figcaption">Alternative ways of visualizing the smooth
term.</div>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses"></a>
</h4>
<p>In the cognition dataset, the responses relating to domain 2 are
binomially distributed. We will use the first trial to illustrate how
such data can be modeled.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"21"</span><span class="op">)</span></span></code></pre></div>
<p>Again we can fit this model using <code>gamm4</code>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>  random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can look at the summary output as before.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    975.7     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2548  0.0786  0.1946  0.4248  0.8213 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2306   0.4802  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9695   0.9846  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; X(Intercept)   2.8115     0.2034  13.825  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Xs(x)Fx1      -1.4110     0.4242  -3.327 0.000879 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 -0.440</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: binomial </span></span>
<span><span class="co">#&gt; Link function: logit </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   2.8115     0.1662   16.91   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;       edf Ref.df Chi.sq p-value    </span></span>
<span><span class="co">#&gt; s(x) 2.14   2.14  113.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.116   </span></span>
<span><span class="co">#&gt; glmer.ML = 908.96  Scale est. = 1         n = 1600</span></span></code></pre></div>
<p>And we can plot the smooth term. The diagnostic plot is not very
useful in the binomial case, so we omit it.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gamm4-binomial-1.png" alt="Smooth term estimated by gamm4."><div class="figcaption">Smooth term estimated by gamm4.</div>
</div>
<p>Again the <code>galamm</code> syntax is similar, but it puts the
random effect specification into the model formula.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span></code></pre></div>
<p>The estimates are very similar, although not identical. The
difference in deviance is due to differences in the way deviance is
defined. The call <code>deviance(mod_gamm4$mer)</code> gives the same
value as in the summary for the model fitted with galamm.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    908.8     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2237  0.0792  0.1947  0.4245  0.8226 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2316   0.4813  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9387   0.9688  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)    2.808     0.1956  14.354 9.989e-47</span></span>
<span><span class="co">#&gt; s(x)Fx1       -1.406     0.4134  -3.402 6.697e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x) 2.124  2.124    114  &lt;2e-16</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gamm-binomial-1.png" alt="Smooth term estimated with galamm."><div class="figcaption">Smooth term estimated with galamm.</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="generalized-additive-models-with-factor-structures">Generalized Additive Models with Factor Structures<a class="anchor" aria-label="anchor" href="#generalized-additive-models-with-factor-structures"></a>
</h3>
<p>We now add factor structures to the GAMMs. These are the types of
models that neither <code>gamm4</code> nor <code>mgcv</code> are able to
estimate (at least without lots of manual hacking), and where
<code>galamm</code> provides new functionality.</p>
<div class="section level4">
<h4 id="gaussian-responses-1">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses-1"></a>
</h4>
<p>To illustrate basic usage, we continue with the cognition data, but
now use all items of cognitive domain 1. These are all conditionally
normal distributed.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>We now need a factor model to associate the underlying latent trait
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>η</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>
with the measurements
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_{i}</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mi>i</mi></msub><mo>+</mo><msub><mi>λ</mi><mi>i</mi></msub><mi>η</mi><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
</annotation></semantics></math></p>
<p>In the structural model, we have a smooth term for the relationship
between the latent trait and x, and we have random intercepts for a
given timepoint within subject
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\zeta^{(2)}</annotation></semantics></math>,
and for a given subject across timepoints
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>3</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\zeta^{(3)}</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>=</mo><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>+</mo><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>3</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\eta = h(x) + \zeta^{(2)} + \zeta^{(3)}.
</annotation></semantics></math></p>
<p>The reduced form of the model is</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mi>i</mi></msub><mo>+</mo><msub><mi>λ</mi><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">{</mo><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>+</mo><msup><mi>ζ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>3</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">}</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
y_{i} = \beta_{i} + \lambda_{i} \left\{ h(x) + \zeta^{(2)} + \zeta^{(3)} \right\} + \epsilon_{i}
</annotation></semantics></math></p>
<p>We will use a varying-coefficient term, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">h(x)</annotation></semantics></math>
is being interpreted as a regression coefficient for the effect of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\lambda_{i}</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_{i}</annotation></semantics></math>,
and the regression term varies with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.
In contrast to <span class="citation">Hastie and Tibshirani (<a href="#ref-hastieVaryingCoefficientModels1993">1993</a>)</span> and
other uses of varying-coefficient terms, however, in this case the
predictor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>λ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\lambda_{i}</annotation></semantics></math>
is a model parameter. We have three items loading in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>η</mi><annotation encoding="application/x-tex">\eta</annotation></semantics></math>
and fix the first loading to 1 for identifiability, so the loading
matrix is as follows:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">loading_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1]</span></span>
<span><span class="co">#&gt; [1,]    1</span></span>
<span><span class="co">#&gt; [2,]   NA</span></span>
<span><span class="co">#&gt; [3,]   NA</span></span></code></pre></div>
<p>We provide thin wrappers around the <code><a href="../reference/sl.html">s()</a></code> and
<code><a href="../reference/t2l.html">t2()</a></code> functions from <code>mgcv</code> to support factor
loadings in smooth terms. The wrappers are named <code><a href="../reference/sl.html">sl()</a></code> and
<code><a href="../reference/t2l.html">t2l()</a></code> to avoid namespace conflicts with <code>mgcv</code>
and <code>gamm4</code>, and the last letter “l” stands for “loading”. In
this example, we set <code>factor = "item"</code> to specify that the
loadings to be applied are identified by the “item” variable. Using
<code>mgcv</code>’s <code>by</code> variable would also work in this
particular case, i.e., replacing <code>sl(x, factor = "loading")</code>
with <code>s(x, by = loading)</code>. However, in most cases this would
lead to identifiability issues due to the way varying-coefficient terms
are set up by <code>mgcv</code>, so <code>galamm</code> provides an
additional <code>factor</code> argument which alleviates most of these
issues.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, factor <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">loading_matrix</span>,</span>
<span>  factor <span class="op">=</span> <span class="st">"loading"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We print the model summary below. In the data simulation, the factor
loadings were set to 1, 1.4, and 0.3, respectively, and this is very
well recovered. Furthermore, the ground truth standard deviation at the
<code>id</code> level was 1, at the <code>timepoint</code> level it was
0.5, and the residual standard deviation was 0.1. The estimates are
close to these values. Real data will typically not have this strong
signal, but based on these results, there are no clear indications that
the model is implemented incorrectly.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, factor = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   -918.2   -853.4    469.1   -938.2     4790 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt;  0.693 10.402 26.734 35.728 51.878 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading       SE</span></span>
<span><span class="co">#&gt; lambda1  1.0000        .</span></span>
<span><span class="co">#&gt; lambda2  1.3973 0.003531</span></span>
<span><span class="co">#&gt; lambda3  0.3009 0.002146</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.236886 0.48671 </span></span>
<span><span class="co">#&gt;  id           loading      0.857051 0.92577 </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 2.030613 1.42500 </span></span>
<span><span class="co">#&gt;  Residual                  0.009932 0.09966 </span></span>
<span><span class="co">#&gt; Number of obs: 4800, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; item11            1.2694    0.06663 19.0513 6.412e-81</span></span>
<span><span class="co">#&gt; item12            1.7788    0.09307 19.1128 1.977e-81</span></span>
<span><span class="co">#&gt; item13            0.3797    0.02019 18.8077 6.531e-79</span></span>
<span><span class="co">#&gt; s(x):loadingFx1  -0.1496    0.19977 -0.7488 4.540e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df    F p-value</span></span>
<span><span class="co">#&gt; s(x):loading 8.719  8.719 4469  &lt;2e-16</span></span></code></pre></div>
<p>We also plot the smooth term. Since we had a very large amount of
data, there is essentially no uncertainty about the estimate.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-factor-1.png" alt="Smooth term for GAMM with factor structure."><div class="figcaption">Smooth term for GAMM with factor
structure.</div>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses-1">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses-1"></a>
</h4>
<p>We can now move on to the part of the cognition data that is
conditionally binomially distributed. We consider domain 2, where each
response measures success or not in a single trial. In this case there
are only two items, so we must change the lambda matrix accordingly.
Other than that, and setting <code>family = binomial</code>, the model
is the same as before.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, factor <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="va">binomial</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="st">"loading"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The summary is shown below. The factor loading
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mn>2</mn></msub><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\lambda_{2} = 2</annotation></semantics></math>
was used when simulating the data, and including the uncertainty, our
estimate covers the true value well. Also note that the variation
between individuals (group <code>id</code>) and the variation between
timepoints within individuals (group <code>timepoint:id</code>) gets
lumped together at the <code>id</code> level. The estimated variation at
the <code>timepoint:id</code> level is zero. This is a well-known
phenomenon when fitting mixed models, given book-length treatment in
<span class="citation">Hodges (<a href="#ref-hodgesRichlyParameterizedLinear2013">2013</a>)</span>. In
this case, it is likely due to the fact that we only have two
measurements at each timepoint, and also the fact that we use the
Laplace approximation to integrate over the random effects, and this
approximation may be inaccurate for binomial data with a low number of
repeated observations <span class="citation">(<a href="#ref-joeAccuracyLaplaceApproximation2008">Joe
2008</a>)</span>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, factor = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   1495.5   1538.0   -740.8   1614.8     3193 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -15.8546   0.0279   0.0780   0.1985   1.3948 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading     SE</span></span>
<span><span class="co">#&gt; lambda1   1.000      .</span></span>
<span><span class="co">#&gt; lambda2   2.202 0.3007</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.0000   0.0000  </span></span>
<span><span class="co">#&gt;  id           loading      0.6222   0.7888  </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 1.5388   1.2405  </span></span>
<span><span class="co">#&gt; Number of obs: 3200, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; item21             2.944     0.1903  15.473 5.249e-54</span></span>
<span><span class="co">#&gt; item22             6.319     0.5853  10.796 3.612e-27</span></span>
<span><span class="co">#&gt; s(x):loadingFx1   -1.389     0.2837  -4.897 9.733e-07</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x):loading 2.491  2.491  115.1  &lt;2e-16</span></span></code></pre></div>
<p>The true value 2 for the factor loading is well within the 95 %
confidence limits.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mod</span>, parm <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></span>
<span><span class="co">#&gt;            2.5 %   97.5 %</span></span>
<span><span class="co">#&gt; lambda1 1.612341 2.791192</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="smooth-terms-with-loadings-and-factor-interactions">Smooth Terms with Loadings and Factor Interactions<a class="anchor" aria-label="anchor" href="#smooth-terms-with-loadings-and-factor-interactions"></a>
</h3>
<div class="section level4">
<h4 id="gaussian-responses-2">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses-2"></a>
</h4>
<p>Domain 1 and 3 both have Gaussian responses, and we can model them
jointly.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We also add indicator variables for the two domains.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">dat</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"domain1"</span>, <span class="st">"domain3"</span><span class="op">)</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>We define the loading matrix, now having two columns:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span></span>
<span>  <span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]   NA    0</span></span>
<span><span class="co">#&gt; [3,]   NA    0</span></span>
<span><span class="co">#&gt; [4,]    0    1</span></span>
<span><span class="co">#&gt; [5,]    0   NA</span></span>
<span><span class="co">#&gt; [6,]    0   NA</span></span>
<span><span class="co">#&gt; [7,]    0   NA</span></span></code></pre></div>
<p>Then we define the model. The smooth term is now
<code>sl(x, by = domain, factor = c("ability1", "ability3"))</code>,
indicating that there should be a separate smooth term for each level of
<code>domain</code>, and that the term should be multiplied by the
loading “ability1” or “ability3”. We also set <code>factr = 1e9</code>
to be less strict with regards to convergence than usual, because this
model is hard to estimate.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_byvar</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, by <span class="op">=</span> <span class="va">domain</span>, factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain3</span><span class="op">:</span><span class="va">ability3</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">lmat</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="../reference/galamm_control.html">galamm_control</a></span><span class="op">(</span></span>
<span>    optim_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>factr <span class="op">=</span> <span class="fl">1e9</span>, trace <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                         REPORT <span class="op">=</span> <span class="fl">50</span>, maxit <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; N = 17, M = 20 machine precision = 2.22045e-16</span></span>
<span><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span><span class="co">#&gt; At iterate     0  f=        25324  |proj g|=       9642.6</span></span>
<span><span class="co">#&gt; At iterate    50  f =        136.9  |proj g|=        716.66</span></span>
<span><span class="co">#&gt; At iterate   100  f =      -1054.7  |proj g|=        1485.1</span></span>
<span><span class="co">#&gt; At iterate   150  f =      -1069.1  |proj g|=        29.652</span></span>
<span><span class="co">#&gt; At iterate   200  f =      -1149.1  |proj g|=        920.26</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; iterations 237</span></span>
<span><span class="co">#&gt; function evaluations 262</span></span>
<span><span class="co">#&gt; segments explored during Cauchy searches 240</span></span>
<span><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span><span class="co">#&gt; active bounds at final generalized Cauchy point 0</span></span>
<span><span class="co">#&gt; norm of the final projected gradient 12.214</span></span>
<span><span class="co">#&gt; final function value -1217.78</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; F = -1217.78</span></span>
<span><span class="co">#&gt; final  value -1217.784476 </span></span>
<span><span class="co">#&gt; converged</span></span></code></pre></div>
<p>The summary shows that we have recovered the true values of the
factor loadings well.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_byvar</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, by = domain, factor = c("ability1", "ability3")) +  </span></span>
<span><span class="co">#&gt;     (0 + domain1:ability1 + domain3:ability3 | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; Control: galamm_control(optim_control = list(factr = 1e+09, trace = 3,      REPORT = 50, maxit = 1000))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;  -2399.6  -2267.7   1217.8  -2435.6    11182 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2115.30 -1034.69  -885.55    21.81    50.58 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1       SE ability3        SE</span></span>
<span><span class="co">#&gt; lambda1   1.0000        .        .         .</span></span>
<span><span class="co">#&gt; lambda2   1.3986 0.002569        .         .</span></span>
<span><span class="co">#&gt; lambda3   0.3013 0.002007        .         .</span></span>
<span><span class="co">#&gt; lambda4        .        .   1.0000         .</span></span>
<span><span class="co">#&gt; lambda5        .        .   0.9993 0.0007676</span></span>
<span><span class="co">#&gt; lambda6        .        .   1.0001 0.0007678</span></span>
<span><span class="co">#&gt; lambda7        .        .   1.9995 0.0015686</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name                  Variance Std.Dev. Corr </span></span>
<span><span class="co">#&gt;  timepoint:id domain1:ability1       0.23642 0.4862        </span></span>
<span><span class="co">#&gt;               domain3:ability3       0.28090 0.5300   -0.01</span></span>
<span><span class="co">#&gt;  id           domain1:ability1       3.35470 1.8316        </span></span>
<span><span class="co">#&gt;               domain3:ability3      18.36906 4.2859   0.89 </span></span>
<span><span class="co">#&gt;  Xr.0         s(x):domain3:ability3 87.57641 9.3582        </span></span>
<span><span class="co">#&gt;  Xr           s(x):domain1:ability1 14.33249 3.7858        </span></span>
<span><span class="co">#&gt;  Residual                            0.01007 0.1003        </span></span>
<span><span class="co">#&gt; Number of obs: 11200, groups:  timepoint:id, 1600; id, 200; Xr.0, 8; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                           Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)              -0.004806   0.004670 -1.0291 3.034e-01</span></span>
<span><span class="co">#&gt; domain3                   0.002617   0.007591  0.3448 7.303e-01</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1 -0.057935   0.241216 -0.2402 8.102e-01</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3Fx1  5.563374   0.315030 17.6598 8.553e-70</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df     F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 8.951  8.951  4316  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3 8.988  8.988 59841  &lt;2e-16</span></span></code></pre></div>
<p>We can plot the estimated smooth terms, which recover their simulated
ground truth very well.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-by-factor1-1.png" alt="Estimated smooth term for domain 1 in model with domain 1 and domain 3."><div class="figcaption">Estimated smooth term for domain 1 in model with
domain 1 and domain 3.</div>
</div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-gaussian-by-factor2-1.png" alt="Estimated smooth term for domain 3 in model with domain 1 and domain 3."><div class="figcaption">Estimated smooth term for domain 3 in model with
domain 1 and domain 3.</div>
</div>
</div>
<div class="section level4">
<h4 id="mixed-gaussian-and-binomial-responses">Mixed Gaussian and Binomial Responses<a class="anchor" aria-label="anchor" href="#mixed-gaussian-and-binomial-responses"></a>
</h4>
<p>Domain 1 has Gaussian responses and domain 2 has binomial responses,
and we can model them jointly. For the sake of speed, we include only
two items for each domain.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We also add indicator variables for the two domains.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">dat</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"domain1"</span>, <span class="st">"domain2"</span><span class="op">)</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>We define the loading matrix, now having two columns:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span></span>
<span>  <span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]   NA    0</span></span>
<span><span class="co">#&gt; [3,]   NA    0</span></span>
<span><span class="co">#&gt; [4,]    0    1</span></span>
<span><span class="co">#&gt; [5,]    0   NA</span></span></code></pre></div>
<p>Then we define the model. The smooth term is now
<code>sl(x, by = domain, factor = c("ability1", "ability2"))</code>,
indicating that there should be a separate smooth term for each level of
<code>domain</code>, and that the term should be multiplied by the
loading “ability1” or “ability2”. Because this model has some
convergence issues, we omit the timepoint-level random intercepts in
this example.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_byvar_mixed</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, by <span class="op">=</span> <span class="va">domain</span>, factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain2</span><span class="op">:</span><span class="va">ability2</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">gaussian</span>, <span class="va">binomial</span><span class="op">)</span>,</span>
<span>  family_mapping <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1L</span>, <span class="fl">2L</span><span class="op">)</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">lmat</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="../reference/galamm_control.html">galamm_control</a></span><span class="op">(</span></span>
<span>    optim_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>factr <span class="op">=</span> <span class="fl">1e9</span>, trace <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                         REPORT <span class="op">=</span> <span class="fl">30</span>, maxit <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; N = 12, M = 20 machine precision = 2.22045e-16</span></span>
<span><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span><span class="co">#&gt; At iterate     0  f=       8170.1  |proj g|=       2305.5</span></span>
<span><span class="co">#&gt; At iterate    30  f =       4726.2  |proj g|=        39.814</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; iterations 44</span></span>
<span><span class="co">#&gt; function evaluations 49</span></span>
<span><span class="co">#&gt; segments explored during Cauchy searches 44</span></span>
<span><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span><span class="co">#&gt; active bounds at final generalized Cauchy point 0</span></span>
<span><span class="co">#&gt; norm of the final projected gradient 0.286444</span></span>
<span><span class="co">#&gt; final function value 4725.04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; F = 4725.04</span></span>
<span><span class="co">#&gt; final  value 4725.035302 </span></span>
<span><span class="co">#&gt; converged</span></span></code></pre></div>
<p>We can look at the model summary:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, by = domain, factor = c("ability1", "ability2")) +  </span></span>
<span><span class="co">#&gt;     (0 + domain1:ability1 + domain2:ability2 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; Control: galamm_control(optim_control = list(factr = 1e+09, trace = 3,      REPORT = 30, maxit = 1000))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   9476.1   9566.9  -4725.0  58315.3     7987 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1      SE ability2      SE</span></span>
<span><span class="co">#&gt; lambda1   1.0000       .        .       .</span></span>
<span><span class="co">#&gt; lambda2   1.4082 0.01335        .       .</span></span>
<span><span class="co">#&gt; lambda3   0.2869 0.01040        .       .</span></span>
<span><span class="co">#&gt; lambda4        .       .   1.0000       .</span></span>
<span><span class="co">#&gt; lambda5        .       .   0.7996 0.05898</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name                  Variance Std.Dev. Corr</span></span>
<span><span class="co">#&gt;  id     domain1:ability1      2.4081   1.552        </span></span>
<span><span class="co">#&gt;         domain2:ability2      1.4827   1.218    0.40</span></span>
<span><span class="co">#&gt;  Xr.0   s(x):domain2:ability2 0.8501   0.922        </span></span>
<span><span class="co">#&gt;  Xr     s(x):domain1:ability1 2.2392   1.496        </span></span>
<span><span class="co">#&gt; Number of obs: 8000, groups:  id, 200; Xr.0, 8; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                          Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)               0.04306    0.02253  1.9116 5.593e-02</span></span>
<span><span class="co">#&gt; domain2                   3.23013    0.16886 19.1290 1.449e-81</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1 -0.08920    0.13855 -0.6438 5.197e-01</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2Fx1  2.10045    0.47649  4.4082 1.042e-05</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df   F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 7.865  7.865 880  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2 3.036  3.036 285  &lt;2e-16</span></span></code></pre></div>
<p>We can plot the estimated smooth terms:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-mixed-by-factor1-1.png" alt="Estimated smooth term for domain 1 in mixed response model with domain 1 and domain 2."><div class="figcaption">Estimated smooth term for domain 1 in mixed
response model with domain 1 and domain 2.</div>
</div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="semiparametric-mixed-by-factor2-1.png" alt="Estimated smooth term for domain 1 in mixed response model with domain 1 and domain 2."><div class="figcaption">Estimated smooth term for domain 1 in mixed
response model with domain 1 and domain 2.</div>
</div>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-hastieVaryingCoefficientModels1993" class="csl-entry">
Hastie, Trevor, and Robert Tibshirani. 1993.
<span>“Varying-<span>Coefficient Models</span>.”</span> <em>Journal of
the Royal Statistical Society: Series B (Methodological)</em> 55 (4):
757–79. <a href="https://doi.org/10.1111/j.2517-6161.1993.tb01939.x" class="external-link">https://doi.org/10.1111/j.2517-6161.1993.tb01939.x</a>.
</div>
<div id="ref-hodgesRichlyParameterizedLinear2013" class="csl-entry">
Hodges, James S. 2013. <em>Richly <span>Parameterized Linear Models
Additive</span>, <span>Time Series</span>, and <span>Spatial Models
Using Random Effects</span></em>. 1st ed. Chapman &amp;
<span>Hall</span>/<span>CRC Texts</span> in <span>Statistical
Science</span>. Chapman &amp; Hall.
</div>
<div id="ref-joeAccuracyLaplaceApproximation2008" class="csl-entry">
Joe, Harry. 2008. <span>“Accuracy of <span>Laplace</span> Approximation
for Discrete Response Mixed Models.”</span> <em>Computational Statistics
&amp; Data Analysis</em> 52 (12): 5066–74. <a href="https://doi.org/10.1016/j.csda.2008.05.002" class="external-link">https://doi.org/10.1016/j.csda.2008.05.002</a>.
</div>
<div id="ref-sorensenLongitudinalModelingAgeDependent2023" class="csl-entry">
Sørensen, Øystein, Anders M. Fjell, and Kristine B. Walhovd. 2023.
<span>“Longitudinal <span>Modeling</span> of <span>Age-Dependent Latent
Traits</span> with <span>Generalized Additive Latent</span> and
<span>Mixed Models</span>.”</span> <em>Psychometrika</em> 88 (2):
456–86. <a href="https://doi.org/10.1007/s11336-023-09910-z" class="external-link">https://doi.org/10.1007/s11336-023-09910-z</a>.
</div>
<div id="ref-woodGeneralizedAdditiveModels2017" class="csl-entry">
Wood, Simon N. 2017. <em>Generalized Additive Models: <span>An</span>
Introduction with <span>R</span></em>. 2nd ed. <span>Chapman and
Hall/CRC</span>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Øystein Sørensen.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
