<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="galamm">
<title>Semiparametric Latent Variable Modeling • galamm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semiparametric Latent Variable Modeling">
<meta property="og:description" content="galamm">
<meta property="og:image" content="https://lcbc-uio.github.io/galamm/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">galamm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.1.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/galamm.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/lmm_factor.html">Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/glmm_factor.html">Generalized Linear Mixed Models with Factor Structures</a>
    <a class="dropdown-item" href="../articles/lmm_heteroscedastic.html">Heteroscedastic Linear Mixed Models</a>
    <a class="dropdown-item" href="../articles/latent_observed_interaction.html">Interactions Between Latent and Observed Covariates</a>
    <a class="dropdown-item" href="../articles/mixed_response.html">Models with Mixed Response Types</a>
    <a class="dropdown-item" href="../articles/semiparametric.html">Semiparametric Latent Variable Modeling</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced topics</h6>
    <a class="dropdown-item" href="../articles/scaling.html">Computational Scaling</a>
    <a class="dropdown-item" href="../articles/optimization.html">Optimization</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/LCBC-UiO/galamm/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Semiparametric Latent Variable Modeling</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/LCBC-UiO/galamm/blob/HEAD/vignettes/semiparametric.Rmd" class="external-link"><code>vignettes/semiparametric.Rmd</code></a></small>
      <div class="d-none name"><code>semiparametric.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/LCBC-UiO/galamm" class="external-link">galamm</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">gamm4</span><span class="op">)</span></span></code></pre></div>
<p>This vignette describes how to use <code>galamm</code> to estimate
latent variable models with smooth terms, or equivalently, generalized
additive mixed models with factor structures. The examples are based on
Section 4 and 5 in <span class="citation">Sørensen, Fjell, and Walhovd
(<a href="#ref-sorensenLongitudinalModelingAgeDependent2023" role="doc-biblioref">2023</a>)</span>, but as we cannot share the data,
we have instead simulated somewhat simpler datasets that will be used.
We will gradually add complexity, starting with a simple generalized
additive mixed model. Please refer to the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a> for an overview of the statistical models.</p>
<div class="section level3">
<h3 id="generalized-additive-mixed-models">Generalized Additive Mixed Models<a class="anchor" aria-label="anchor" href="#generalized-additive-mixed-models"></a>
</h3>
<p>We start by showing how <code>galamm</code> can be used to estimated
generalized additive mixed models.</p>
<div class="section level4">
<h4 id="gaussian-responses">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses"></a>
</h4>
<p>The <code>cognition</code> dataset contains simulated data with
measurements of abilities in three cognitive domains.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">cognition</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>For this first example, we focus only on the first item measured for
the first domain.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"11"</span><span class="op">)</span></span></code></pre></div>
<p>Each subject in this dataset has been measured eight times, and we
can plot the measurements as follows:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">x</span>, <span class="va">dat</span><span class="op">$</span><span class="va">y</span>, type <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">"x"</span>, ylab <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">id</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">dd</span> <span class="op">&lt;-</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">id</span> <span class="op">==</span> <span class="va">i</span>, <span class="op">]</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">x</span>, <span class="va">dd</span><span class="op">$</span><span class="va">y</span>, col <span class="op">=</span> <span class="st">"gray"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">x</span>, <span class="va">dat</span><span class="op">$</span><span class="va">y</span>, pch <span class="op">=</span> <span class="fl">20</span>, lwd <span class="op">=</span> <span class="fl">.05</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-spaghetti-plot-1.png" alt=""><p class="caption">Plot of data for domain 1 and item 11.</p>
</div>
<p>We use a generalized additive mixed model with random intercepts per
subject to estimate the function relating <span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span>. In terms of the model framework
outlined in the <a href="https://lcbc-uio.github.io/galamm/articles/galamm.html">introductory
vignette</a>, we model the <span class="math inline">\(i\)</span>th
response from the <span class="math inline">\(j\)</span>th subject
with</p>
<p><span class="math display">\[
y_{ij} = f(x_{ij}) + \eta_{j} + \epsilon_{ij}
\]</span></p>
<p>where <span class="math inline">\(f(x_{ij})\)</span> is a smooth
function to be estimated, <span class="math inline">\(\eta_{j} \sim N(0,
\psi)\)</span> is a random intercept, and <span class="math inline">\(\epsilon_{ij} \sim N(0, \phi)\)</span> is a
residual term.</p>
<p>This model can be estimated using <code>gamm4</code> as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, REML <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>The package <code>gamm4</code> uses <code>lme4</code> to fit the
underlying model, and the resulting model has two components.
<code>mod_gamm4$mer</code> contains the mixed model representation,
whereas in <code>mod_gamm4$gam</code> the fixed and random effects
corresponding to spline coefficients have been converted into single
smooth terms. We can look at the model summary for each:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by maximum likelihood  ['lmerMod']</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3025.2   3052.1  -1507.6   3015.2     1595 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.93755 -0.65215  0.00612  0.62654  3.14289 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id       (Intercept) 0.8551   0.9247  </span></span>
<span><span class="co">#&gt;  Xr       s(x)        2.0341   1.4262  </span></span>
<span><span class="co">#&gt;  Residual             0.2501   0.5001  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error t value</span></span>
<span><span class="co">#&gt; X(Intercept)  1.26938    0.06657  19.067</span></span>
<span><span class="co">#&gt; Xs(x)Fx1     -0.15814    0.20156  -0.785</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 0.000</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: gaussian </span></span>
<span><span class="co">#&gt; Link function: identity </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  1.26938    0.06657   19.07   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df     F p-value    </span></span>
<span><span class="co">#&gt; s(x) 6.681  6.681 324.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.253   </span></span>
<span><span class="co">#&gt; lmer.REML = 3015.2  Scale est. = 0.25012   n = 1600</span></span></code></pre></div>
<p>We can also plot the estimated smooth term:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm4-smooth-1.png" alt=""><p class="caption">Smooth term estimated by gamm4.</p>
</div>
<p>In contrast, invoking the <code>plot</code> function on the mixed
model part gives us a diagnostic plot.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm4-diagnostic-1.png" alt=""><p class="caption">Diagnostic plot for gamm4 model.</p>
</div>
<p>With <code>galamm</code> we use similar argument, but the
<code>random</code> specification is now part of the model formula.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span></span></code></pre></div>
<p>As opposed to <code>gamm4</code>, <code>galamm</code> gives a single
summary. As can be seen, smooth terms are both reported as random
effects, and in a separate line under the header “Approximate
significance of smooth terms:”. Reassuringly, the results from fitting
the model with <code>gamm4</code> and with <code>galamm</code> are
essentially equally, even though they use somewhat different
computational algorithms.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3025.2   3052.1  -1507.6   3015.2     1595 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.93755 -0.65215  0.00612  0.62654  3.14290 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id       (Intercept) 0.8551   0.9247  </span></span>
<span><span class="co">#&gt;  Xr       s(x)        2.0346   1.4264  </span></span>
<span><span class="co">#&gt;  Residual             0.2501   0.5001  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)   1.2694    0.06657 19.0672 4.731e-81</span></span>
<span><span class="co">#&gt; s(x)Fx1      -0.1582    0.20236 -0.7818 4.343e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df     F p-value</span></span>
<span><span class="co">#&gt; s(x) 6.681  6.681 324.9  &lt;2e-16</span></span></code></pre></div>
<p>The <code>plot</code> function now gives us a diagnostic plot, which
by inspection can be seen to be almost identical to the plot produced
from the mixed model part of the <code>gamm4</code> model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-diagnostic-1.png" alt=""><p class="caption">Diagnostic plot for model fitted with galamm.</p>
</div>
<p>In order to plot the smooth term, we use
<code>plot_smooth</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth1-1.png" alt=""><p class="caption">Smooth term estimated with galamm.</p>
</div>
<p>The <code>plot_smooth</code> function is a thin wrapper around the
<code>plot.gam</code> function provided by the <code>mgcv</code> package
<span class="citation">(<a href="#ref-woodGeneralizedAdditiveModels2017a" role="doc-biblioref">Wood
2017</a>)</span>. This means that the arguments used by
<code>plot.gam</code> can be used also here, as see with the examples
below:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>,</span>
<span>  shade <span class="op">=</span> <span class="cn">TRUE</span>, rug <span class="op">=</span> <span class="cn">FALSE</span>, seWithMean <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  shift <span class="op">=</span> <span class="op">+</span><span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth2-1.png" alt=""><p class="caption">Alternative ways of visualizing the smooth term.</p>
</div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-gamm-smooth2-2.png" alt=""><p class="caption">Alternative ways of visualizing the smooth term.</p>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses"></a>
</h4>
<p>In the cognition dataset, the responses relating to domain 2 are
binomially distributed. We will use the first trial to illustrate how
such data can be modeled.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">&amp;</span> <span class="va">item</span> <span class="op">==</span> <span class="st">"21"</span><span class="op">)</span></span></code></pre></div>
<p>Again we can fit this model using <code>gamm4</code>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_gamm4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gamm4/man/gamm4.html" class="external-link">gamm4</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>  random <span class="op">=</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can look at the summary output as before.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">mer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    975.7     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2547  0.0786  0.1946  0.4248  0.8213 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2306   0.4802  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9694   0.9846  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; X(Intercept)   2.8115     0.2034  13.824  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Xs(x)Fx1      -1.4110     0.4242  -3.326  0.00088 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;          X(Int)</span></span>
<span><span class="co">#&gt; Xs(x)Fx1 -0.440</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Family: binomial </span></span>
<span><span class="co">#&gt; Link function: logit </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Formula:</span></span>
<span><span class="co">#&gt; y ~ s(x)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Parametric coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   2.8115     0.1662   16.91   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;       edf Ref.df Chi.sq p-value    </span></span>
<span><span class="co">#&gt; s(x) 2.14   2.14  113.9  &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; R-sq.(adj) =  0.116   </span></span>
<span><span class="co">#&gt; glmer.ML = 908.96  Scale est. = 1         n = 1600</span></span></code></pre></div>
<p>And we can plot the smooth term. The diagnostic plot is not very
useful in the binomial case, so we omit it.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mod_gamm4</span><span class="op">$</span><span class="va">gam</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gamm4-binomial-1.png" alt=""><p class="caption">Smooth term estimated by gamm4.</p>
</div>
<p>Again the <code>galamm</code> syntax is similar, but it puts the
random effect specification into the model formula.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="../reference/sl.html">s</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span></code></pre></div>
<p>The estimates are very similar, although not identical. The
difference in deviance is due to differences in the way deviance is
defined. The call <code>deviance(mod_gamm4$mer)</code> gives the same
value as in the summary for the model fitted with galamm.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ s(x) + (1 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    983.7   1005.2   -487.8    908.8     1596 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -8.2237  0.0792  0.1947  0.4245  0.8226 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  id     (Intercept) 0.2316   0.4813  </span></span>
<span><span class="co">#&gt;  Xr     s(x)        0.9387   0.9688  </span></span>
<span><span class="co">#&gt; Number of obs: 1600, groups:  id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)    2.808     0.1956  14.354 9.989e-47</span></span>
<span><span class="co">#&gt; s(x)Fx1       -1.406     0.4134  -3.402 6.697e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;        edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x) 2.124  2.124    114  &lt;2e-16</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gamm-binomial-1.png" alt=""><p class="caption">Smooth term estimated with galamm.</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="generalized-additive-models-with-factor-structures">Generalized Additive Models with Factor Structures<a class="anchor" aria-label="anchor" href="#generalized-additive-models-with-factor-structures"></a>
</h3>
<p>We now add factor structures to the GAMMs. These are the types of
models that neither <code>gamm4</code> nor <code>mgcv</code> are able to
estimate (at least without lots of manual hacking), and where
<code>galamm</code> provides new functionality.</p>
<div class="section level4">
<h4 id="gaussian-responses-1">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses-1"></a>
</h4>
<p>To illustrate basic usage, we continue with the cognition data, but
now use all items of cognitive domain 1. These are all conditionally
normal distributed.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span></span>
<span><span class="co">#&gt;   id domain          x timepoint item trials          y</span></span>
<span><span class="co">#&gt; 1  1      1 0.06475113         1   11      1 0.16788973</span></span>
<span><span class="co">#&gt; 2  1      1 0.06475113         1   12      1 0.08897838</span></span>
<span><span class="co">#&gt; 3  1      1 0.06475113         1   13      1 0.03162123</span></span>
<span><span class="co">#&gt; 4  1      1 0.15766278         2   11      1 0.46598362</span></span>
<span><span class="co">#&gt; 5  1      1 0.15766278         2   12      1 0.84564656</span></span>
<span><span class="co">#&gt; 6  1      1 0.15766278         2   13      1 0.20549872</span></span></code></pre></div>
<p>We now need a factor model to associate the underlying latent trait
<span class="math inline">\(\eta\)</span> with the measurements <span class="math inline">\(y_{i}\)</span>:</p>
<p><span class="math display">\[
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
\]</span></p>
<p>In the structural model, we have a smooth term for the relationship
between the latent trait and x, and we have random intercepts for a
given timepoint within subject <span class="math inline">\(\zeta^{(2)}\)</span>, and for a given subject
across timepoints <span class="math inline">\(\zeta^{(3)}\)</span>.</p>
<p><span class="math display">\[
\eta = h(x) + \zeta^{(2)} + \zeta^{(3)}.
\]</span></p>
<p>The reduced form of the model is</p>
<p><span class="math display">\[
y_{i} = \beta_{i} + \lambda_{i} \left\{ h(x) + \zeta^{(2)} + \zeta^{(3)}
\right\} + \epsilon_{i}
\]</span></p>
<p>We will use a varying-coefficient term, where <span class="math inline">\(h(x)\)</span> is being interpreted as a regression
coefficient for the effect of <span class="math inline">\(\lambda_{i}\)</span> on <span class="math inline">\(y_{i}\)</span>, and the regression term varies
with <span class="math inline">\(x\)</span>. In contrast to <span class="citation">Hastie and Tibshirani (<a href="#ref-hastieVaryingCoefficientModels1993" role="doc-biblioref">1993</a>)</span> and other uses of
varying-coefficient terms, however, in this case the predictor <span class="math inline">\(\lambda_{i}\)</span> is a model parameter. We have
three items loading in <span class="math inline">\(\eta\)</span> and fix
the first loading to 1 for identifiability, so the loading matrix is as
follows:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">loading_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1]</span></span>
<span><span class="co">#&gt; [1,]    1</span></span>
<span><span class="co">#&gt; [2,]   NA</span></span>
<span><span class="co">#&gt; [3,]   NA</span></span></code></pre></div>
<p>We provide thin wrappers around the <code><a href="../reference/sl.html">s()</a></code> and
<code><a href="../reference/t2l.html">t2()</a></code> functions from <code>mgcv</code> to support factor
loadings in smooth terms. The wrappers are named <code><a href="../reference/sl.html">sl()</a></code> and
<code><a href="../reference/t2l.html">t2l()</a></code> to avoid namespace conflicts with <code>mgcv</code>
and <code>gamm4</code>, and the last letter “l” stands for “loading”. In
this example, we set <code>factor = "item"</code> to specify that the
loadings to be applied are identified by the “item” variable. Using
<code>mgcv</code>’s <code>by</code> variable would also work in this
particular case, i.e., replacing <code>sl(x, factor = "loading")</code>
with <code>s(x, by = loading)</code>. However, in most cases this would
lead to identifiability issues due to the way varying-coefficient terms
are set up by <code>mgcv</code>, so <code>galamm</code> provides an
additional <code>factor</code> argument which alleviates most of these
issues.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, factor <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">loading_matrix</span>,</span>
<span>  factor <span class="op">=</span> <span class="st">"loading"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We print the model summary below. In the data simulation, the factor
loadings were set to 1, 1.4, and 0.3, respectively, and this is very
well recovered. Furthermore, the ground truth standard deviation at the
<code>id</code> level was 1, at the <code>timepoint</code> level it was
0.5, and the residual standard deviation was 0.1. The estimates are
close to these values. Real data will typically not have this strong
signal, but based on these results, there are no clear indications that
the model is implemented incorrectly.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, factor = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   -918.2   -853.4    469.1   -938.2     4790 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt;  -2.76   6.46  13.58  23.31  35.84 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading       SE</span></span>
<span><span class="co">#&gt; lambda1  1.0000        .</span></span>
<span><span class="co">#&gt; lambda2  1.3973 0.003531</span></span>
<span><span class="co">#&gt; lambda3  0.3009 0.002146</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.236886 0.48671 </span></span>
<span><span class="co">#&gt;  id           loading      0.857051 0.92577 </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 2.030613 1.42500 </span></span>
<span><span class="co">#&gt;  Residual                  0.009932 0.09966 </span></span>
<span><span class="co">#&gt; Number of obs: 4800, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; item11            1.2694    0.06663 19.0513 6.412e-81</span></span>
<span><span class="co">#&gt; item12            1.7788    0.09307 19.1128 1.977e-81</span></span>
<span><span class="co">#&gt; item13            0.3797    0.02019 18.8077 6.531e-79</span></span>
<span><span class="co">#&gt; s(x):loadingFx1  -0.1496    0.19977 -0.7488 4.540e-01</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df    F p-value</span></span>
<span><span class="co">#&gt; s(x):loading 8.719  8.719 4469  &lt;2e-16</span></span></code></pre></div>
<p>We also plot the smooth term. Since we had a very large amount of
data, there is essentially no uncertainty about the estimate.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-factor-1.png" alt=""><p class="caption">Smooth term for GAMM with factor structure.</p>
</div>
</div>
<div class="section level4">
<h4 id="binomial-responses-1">Binomial Responses<a class="anchor" aria-label="anchor" href="#binomial-responses-1"></a>
</h4>
<p>We can now move on to the part of the cognition data that is
conditionally binomially distributed. We consider domain 2, where each
response measures success or not in a single trial. In this case there
are only two items, so we must change the lambda matrix accordingly.
Other than that, and setting <code>family = binomial</code>, the model
is the same as before.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">item</span> <span class="op">+</span> <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, factor <span class="op">=</span> <span class="st">"loading"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">loading</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="va">binomial</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="cn">NA</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  factor <span class="op">=</span> <span class="st">"loading"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The summary is shown below. The factor loading <span class="math inline">\(\lambda_{2} = 2\)</span> was used when simulating
the data, and including the uncertainty, our estimate covers the true
value well. Also note that the variation between individuals (group
<code>id</code>) and the variation between timepoints within individuals
(group <code>timepoint:id</code>) gets lumped together at the
<code>id</code> level. The estimated variation at the
<code>timepoint:id</code> level is zero. This is a well-known phenomenon
when fitting mixed models, given book-length treatment in <span class="citation">Hodges (<a href="#ref-hodgesRichlyParameterizedLinear2013" role="doc-biblioref">2013</a>)</span>. In this case, it is likely due to
the fact that we only have two measurements at each timepoint, and also
the fact that we use the Laplace approximation to integrate over the
random effects, and this approximation may be inaccurate for binomial
data with a low number of repeated observations <span class="citation">(<a href="#ref-joeAccuracyLaplaceApproximation2008" role="doc-biblioref">Joe 2008</a>)</span>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ 0 + item + sl(x, factor = "loading") + (0 + loading | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   1495.5   1538.0   -740.8   1614.8     3193 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -15.8546   0.0279   0.0780   0.1985   1.3948 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         loading     SE</span></span>
<span><span class="co">#&gt; lambda1   1.000      .</span></span>
<span><span class="co">#&gt; lambda2   2.202 0.3007</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name         Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  timepoint:id loading      0.0000   0.0000  </span></span>
<span><span class="co">#&gt;  id           loading      0.6222   0.7888  </span></span>
<span><span class="co">#&gt;  Xr           s(x):loading 1.5388   1.2405  </span></span>
<span><span class="co">#&gt; Number of obs: 3200, groups:  timepoint:id, 1600; id, 200; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; item21             2.944     0.1903  15.473 5.249e-54</span></span>
<span><span class="co">#&gt; item22             6.319     0.5853  10.796 3.612e-27</span></span>
<span><span class="co">#&gt; s(x):loadingFx1   -1.389     0.2837  -4.897 9.733e-07</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                edf Ref.df Chi.sq p-value</span></span>
<span><span class="co">#&gt; s(x):loading 2.491  2.491  115.1  &lt;2e-16</span></span></code></pre></div>
<p>The true value 2 for the factor loading is well within the 95 %
confidence limits.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mod</span>, parm <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></span>
<span><span class="co">#&gt;            2.5 %   97.5 %</span></span>
<span><span class="co">#&gt; lambda1 1.612341 2.791192</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="smooth-terms-with-loadings-and-factor-interactions">Smooth Terms with Loadings and Factor Interactions<a class="anchor" aria-label="anchor" href="#smooth-terms-with-loadings-and-factor-interactions"></a>
</h3>
<div class="section level4">
<h4 id="gaussian-responses-2">Gaussian Responses<a class="anchor" aria-label="anchor" href="#gaussian-responses-2"></a>
</h4>
<p>Domain 1 and 3 both have Gaussian responses, and we can model them
jointly.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We also add indicator variables for the two domains.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">dat</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"domain1"</span>, <span class="st">"domain3"</span><span class="op">)</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>We define the loading matrix, now having two columns:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span></span>
<span>  <span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]   NA    0</span></span>
<span><span class="co">#&gt; [3,]   NA    0</span></span>
<span><span class="co">#&gt; [4,]    0    1</span></span>
<span><span class="co">#&gt; [5,]    0   NA</span></span>
<span><span class="co">#&gt; [6,]    0   NA</span></span>
<span><span class="co">#&gt; [7,]    0   NA</span></span></code></pre></div>
<p>Then we define the model. The smooth term is now
<code>sl(x, by = domain, factor = c("ability1", "ability3"))</code>,
indicating that there should be a separate smooth term for each level of
<code>domain</code>, and that the term should be multiplied by the
loading “ability1” or “ability3”. We also set <code>factr = 1e9</code>
to be less strict with regards to convergence than usual, because this
model is hard to estimate.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_byvar</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, by <span class="op">=</span> <span class="va">domain</span>, factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain3</span><span class="op">:</span><span class="va">ability3</span> <span class="op">|</span> <span class="va">id</span> <span class="op">/</span> <span class="va">timepoint</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">lmat</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability3"</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="../reference/galamm_control.html">galamm_control</a></span><span class="op">(</span></span>
<span>    optim_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>factr <span class="op">=</span> <span class="fl">1e9</span>, trace <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                         REPORT <span class="op">=</span> <span class="fl">50</span>, maxit <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; N = 17, M = 20 machine precision = 2.22045e-16</span></span>
<span><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span><span class="co">#&gt; At iterate     0  f=        25324  |proj g|=       9642.6</span></span>
<span><span class="co">#&gt; At iterate    50  f =        136.9  |proj g|=        716.66</span></span>
<span><span class="co">#&gt; At iterate   100  f =      -1062.7  |proj g|=        121.27</span></span>
<span><span class="co">#&gt; At iterate   150  f =      -1069.4  |proj g|=        155.18</span></span>
<span><span class="co">#&gt; At iterate   200  f =      -1147.3  |proj g|=         84.96</span></span>
<span><span class="co">#&gt; At iterate   250  f =      -1147.6  |proj g|=        42.374</span></span>
<span><span class="co">#&gt; At iterate   300  f =      -1209.4  |proj g|=        66.759</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; iterations 338</span></span>
<span><span class="co">#&gt; function evaluations 377</span></span>
<span><span class="co">#&gt; segments explored during Cauchy searches 341</span></span>
<span><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span><span class="co">#&gt; active bounds at final generalized Cauchy point 0</span></span>
<span><span class="co">#&gt; norm of the final projected gradient 2.43961</span></span>
<span><span class="co">#&gt; final function value -1217.34</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; F = -1217.34</span></span>
<span><span class="co">#&gt; final  value -1217.343067 </span></span>
<span><span class="co">#&gt; converged</span></span></code></pre></div>
<p>The summary shows that we have recovered the true values of the
factor loadings well.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_byvar</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, by = domain, factor = c("ability1", "ability3")) +  </span></span>
<span><span class="co">#&gt;     (0 + domain1:ability1 + domain3:ability3 | id/timepoint)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; Control: galamm_control(optim_control = list(factr = 1e+09, trace = 3,      REPORT = 50, maxit = 1000))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;  -2398.7  -2266.9   1217.3  -2434.7    11182 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2115.14 -1034.62  -885.39    22.95    51.96 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1       SE ability3        SE</span></span>
<span><span class="co">#&gt; lambda1   1.0000        .        .         .</span></span>
<span><span class="co">#&gt; lambda2   1.3986 0.002569        .         .</span></span>
<span><span class="co">#&gt; lambda3   0.3014 0.002007        .         .</span></span>
<span><span class="co">#&gt; lambda4        .        .   1.0000         .</span></span>
<span><span class="co">#&gt; lambda5        .        .   0.9993 0.0007676</span></span>
<span><span class="co">#&gt; lambda6        .        .   1.0001 0.0007679</span></span>
<span><span class="co">#&gt; lambda7        .        .   1.9995 0.0015687</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups       Name                  Variance Std.Dev. Corr </span></span>
<span><span class="co">#&gt;  timepoint:id domain1:ability1       0.23662 0.4864        </span></span>
<span><span class="co">#&gt;               domain3:ability3       0.28037 0.5295   -0.01</span></span>
<span><span class="co">#&gt;  id           domain1:ability1       3.35242 1.8310        </span></span>
<span><span class="co">#&gt;               domain3:ability3      18.30509 4.2784   0.89 </span></span>
<span><span class="co">#&gt;  Xr.0         s(x):domain3:ability3 86.88159 9.3210        </span></span>
<span><span class="co">#&gt;  Xr           s(x):domain1:ability1 16.07526 4.0094        </span></span>
<span><span class="co">#&gt;  Residual                            0.01007 0.1003        </span></span>
<span><span class="co">#&gt; Number of obs: 11200, groups:  timepoint:id, 1600; id, 200; Xr.0, 8; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                           Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)              -0.004847   0.004671 -1.0377 2.994e-01</span></span>
<span><span class="co">#&gt; domain3                   0.002629   0.007592  0.3463 7.291e-01</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1 -0.057658   0.245575 -0.2348 8.144e-01</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3Fx1  5.570914   0.314703 17.7021 4.037e-70</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df     F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 8.956  8.956  4313  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain3:ability3 8.988  8.988 59831  &lt;2e-16</span></span></code></pre></div>
<p>We can plot the estimated smooth terms, which recover their simulated
ground truth very well.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-by-factor1-1.png" alt=""><p class="caption">Estimated smooth term for domain 1 in model with
domain 1 and domain 3.</p>
</div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-gaussian-by-factor2-1.png" alt=""><p class="caption">Estimated smooth term for domain 3 in model with
domain 1 and domain 3.</p>
</div>
</div>
<div class="section level4">
<h4 id="mixed-gaussian-and-binomial-responses">Mixed Gaussian and Binomial Responses<a class="anchor" aria-label="anchor" href="#mixed-gaussian-and-binomial-responses"></a>
</h4>
<p>Domain 1 has Gaussian responses and domain 2 has binomial responses,
and we can model them jointly. For the sake of speed, we include only
two items for each domain.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">cognition</span>, <span class="va">domain</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We also add indicator variables for the two domains.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">dat</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">domain</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"domain1"</span>, <span class="st">"domain2"</span><span class="op">)</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>We define the loading matrix, now having two columns:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">lmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fl">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>    <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="cn">NA</span></span>
<span>  <span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1] [,2]</span></span>
<span><span class="co">#&gt; [1,]    1    0</span></span>
<span><span class="co">#&gt; [2,]   NA    0</span></span>
<span><span class="co">#&gt; [3,]   NA    0</span></span>
<span><span class="co">#&gt; [4,]    0    1</span></span>
<span><span class="co">#&gt; [5,]    0   NA</span></span></code></pre></div>
<p>Then we define the model. The smooth term is now
<code>sl(x, by = domain, factor = c("ability1", "ability2"))</code>,
indicating that there should be a separate smooth term for each level of
<code>domain</code>, and that the term should be multiplied by the
loading “ability1” or “ability2”. Because this model has some
convergence issues, we omit the timepoint-level random intercepts in
this example.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod_byvar_mixed</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/galamm.html">galamm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">domain</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="../reference/sl.html">sl</a></span><span class="op">(</span><span class="va">x</span>, by <span class="op">=</span> <span class="va">domain</span>, factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">domain1</span><span class="op">:</span><span class="va">ability1</span> <span class="op">+</span> <span class="va">domain2</span><span class="op">:</span><span class="va">ability2</span> <span class="op">|</span> <span class="va">id</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dat</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">gaussian</span>, <span class="va">binomial</span><span class="op">)</span>,</span>
<span>  family_mapping <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">domain</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1L</span>, <span class="fl">2L</span><span class="op">)</span>,</span>
<span>  load.var <span class="op">=</span> <span class="st">"item"</span>,</span>
<span>  lambda <span class="op">=</span> <span class="va">lmat</span>,</span>
<span>  factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ability1"</span>, <span class="st">"ability2"</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="../reference/galamm_control.html">galamm_control</a></span><span class="op">(</span></span>
<span>    optim_control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>factr <span class="op">=</span> <span class="fl">1e9</span>, trace <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                         REPORT <span class="op">=</span> <span class="fl">30</span>, maxit <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; N = 12, M = 20 machine precision = 2.22045e-16</span></span>
<span><span class="co">#&gt; At X0, 0 variables are exactly at the bounds</span></span>
<span><span class="co">#&gt; At iterate     0  f=       8170.1  |proj g|=       2305.5</span></span>
<span><span class="co">#&gt; At iterate    30  f =       4726.2  |proj g|=        39.814</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; iterations 44</span></span>
<span><span class="co">#&gt; function evaluations 49</span></span>
<span><span class="co">#&gt; segments explored during Cauchy searches 44</span></span>
<span><span class="co">#&gt; BFGS updates skipped 0</span></span>
<span><span class="co">#&gt; active bounds at final generalized Cauchy point 0</span></span>
<span><span class="co">#&gt; norm of the final projected gradient 0.286444</span></span>
<span><span class="co">#&gt; final function value 4725.04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; F = 4725.04</span></span>
<span><span class="co">#&gt; final  value 4725.035302 </span></span>
<span><span class="co">#&gt; converged</span></span></code></pre></div>
<p>We can look at the model summary:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; GALAMM fit by maximum marginal likelihood.</span></span>
<span><span class="co">#&gt; Formula: y ~ domain + sl(x, by = domain, factor = c("ability1", "ability2")) +      (0 + domain1:ability1 + domain2:ability2 | id)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; Control: galamm_control(optim_control = list(factr = 1e+09, trace = 3,      REPORT = 30, maxit = 1000))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   9476.1   9566.9  -4725.0  98981.3     7987 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -13.543   0.426   1.987   6.127  18.637 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Lambda:</span></span>
<span><span class="co">#&gt;         ability1      SE ability2      SE</span></span>
<span><span class="co">#&gt; lambda1   1.0000       .        .       .</span></span>
<span><span class="co">#&gt; lambda2   1.4082 0.01335        .       .</span></span>
<span><span class="co">#&gt; lambda3   0.2869 0.01040        .       .</span></span>
<span><span class="co">#&gt; lambda4        .       .   1.0000       .</span></span>
<span><span class="co">#&gt; lambda5        .       .   0.7996 0.05898</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name                  Variance Std.Dev. Corr</span></span>
<span><span class="co">#&gt;  id     domain1:ability1      2.4081   1.552        </span></span>
<span><span class="co">#&gt;         domain2:ability2      1.4827   1.218    0.40</span></span>
<span><span class="co">#&gt;  Xr.0   s(x):domain2:ability2 0.8501   0.922        </span></span>
<span><span class="co">#&gt;  Xr     s(x):domain1:ability1 2.2392   1.496        </span></span>
<span><span class="co">#&gt; Number of obs: 8000, groups:  id, 200; Xr.0, 8; Xr, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                          Estimate Std. Error z value  Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)               0.04306    0.02253  1.9116 5.593e-02</span></span>
<span><span class="co">#&gt; domain2                   3.23013    0.16886 19.1290 1.449e-81</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1Fx1 -0.08920    0.13855 -0.6438 5.197e-01</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2Fx1  2.10045    0.47649  4.4082 1.042e-05</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate significance of smooth terms:</span></span>
<span><span class="co">#&gt;                         edf Ref.df    F p-value</span></span>
<span><span class="co">#&gt; s(x):domain1:ability1 7.865  7.865  880  &lt;2e-16</span></span>
<span><span class="co">#&gt; s(x):domain2:ability2 6.442  6.442 8007  &lt;2e-16</span></span></code></pre></div>
<p>We can plot the estimated smooth terms:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-mixed-by-factor1-1.png" alt=""><p class="caption">Estimated smooth term for domain 1 in mixed response
model with domain 1 and domain 2.</p>
</div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_smooth.galamm.html">plot_smooth</a></span><span class="op">(</span><span class="va">mod_byvar_mixed</span>, scale <span class="op">=</span> <span class="fl">0</span>, select <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="semiparametric-mixed-by-factor2-1.png" alt=""><p class="caption">Estimated smooth term for domain 1 in mixed response
model with domain 1 and domain 2.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-hastieVaryingCoefficientModels1993" class="csl-entry">
Hastie, Trevor, and Robert Tibshirani. 1993.
<span>“Varying-<span>Coefficient Models</span>.”</span> <em>Journal of
the Royal Statistical Society: Series B (Methodological)</em> 55 (4):
757–79. <a href="https://doi.org/10.1111/j.2517-6161.1993.tb01939.x" class="external-link">https://doi.org/10.1111/j.2517-6161.1993.tb01939.x</a>.
</div>
<div id="ref-hodgesRichlyParameterizedLinear2013" class="csl-entry">
Hodges, James S. 2013. <em>Richly <span>Parameterized Linear Models
Additive</span>, <span>Time Series</span>, and <span>Spatial Models
Using Random Effects</span></em>. 1st ed. Chapman &amp;
<span>Hall</span>/<span>CRC Texts</span> in <span>Statistical
Science</span>. <span>Chapman &amp; Hall</span>.
</div>
<div id="ref-joeAccuracyLaplaceApproximation2008" class="csl-entry">
Joe, Harry. 2008. <span>“Accuracy of <span>Laplace</span> Approximation
for Discrete Response Mixed Models.”</span> <em>Computational Statistics
&amp; Data Analysis</em> 52 (12): 5066–74. <a href="https://doi.org/10.1016/j.csda.2008.05.002" class="external-link">https://doi.org/10.1016/j.csda.2008.05.002</a>.
</div>
<div id="ref-sorensenLongitudinalModelingAgeDependent2023" class="csl-entry">
Sørensen, Øystein, Anders M. Fjell, and Kristine B. Walhovd. 2023.
<span>“Longitudinal <span>Modeling</span> of <span>Age-Dependent Latent
Traits</span> with <span>Generalized Additive Latent</span> and
<span>Mixed Models</span>.”</span> <em>Psychometrika</em> 88 (2):
456–86. <a href="https://doi.org/10.1007/s11336-023-09910-z" class="external-link">https://doi.org/10.1007/s11336-023-09910-z</a>.
</div>
<div id="ref-woodGeneralizedAdditiveModels2017a" class="csl-entry">
Wood, Simon N. 2017. <em>Generalized Additive Models: <span>An</span>
Introduction with <span>R</span></em>. 2nd ed. <span>Chapman and
Hall/CRC</span>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Øystein Sørensen.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
