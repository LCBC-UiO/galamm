---
title: "Semiparametric Latent Variable Modeling"
output:
  rmarkdown::html_vignette:
    fig_width: 6
    fig_height: 4
bibliography: ../inst/REFERENCES.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Semiparametric Latent Variable Modeling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(galamm)
library(gamm4)
library(ggplot2)
theme_set(theme_bw())
```

This vignette describes how to use galamm to estimate latent variable models with smooth terms. The examples are based on Section 4 and 5 in @sorensenLongitudinalModelingAgeDependent2023, but as we cannot share the data, we have instead simulated somewhat simpler datasets that will be used. We will gradually add complexity, starting with a simple generalized additive mixed.

## Generalized Additive Mixed Models

### Gaussian Responses

The `cognition` dataset contains simulated data with measurements of abilities in three cognitive domains.

```{r}
head(cognition)
```

For this first example, we focus only on the first item measured for the first domain.

```{r}
dat <- subset(cognition, domain == 1 & item == 1)
```

Each subject in this dataset has been measured eight times, and we can plot the measurements as follows:

```{r}
ggplot(dat, aes(x = x, y = y, group = id)) +
  geom_point(size = .1) +
  geom_line(alpha = .3)
```

We use a generalized additive mixed model with random intercepts per subject to estimate the function relating $x$ to $y$. In terms of the model framework outlined in the [introductory vignette](https://lcbc-uio.github.io/galamm/articles/galamm.html), we model the $i$th response from the $j$th subject with

$$
y_{ij} = f(x_{ij}) + \eta_{j} + \epsilon_{ij}
$$

where $f(x_{ij})$ is a smooth function to be estimated, $\eta_{j} \sim N(0, \psi)$ is a random intercept, and $\epsilon_{ij} \sim N(0, \phi)$ is a residual term.

This model can be estimated using gamm4 as follows:

```{r}
mod_gamm4 <- gamm4(y ~ s(x), random = ~ (1 | id), data = dat, REML = FALSE)
```

The resulting estimated smooth term looks sensible.

```{r}
summary(mod_gamm4$mer)
summary(mod_gamm4$gam)
plot(mod_gamm4$gam)
```

With galamm we use similar argument, but the `random` specification is now part of the model formula.

```{r}
mod <- galamm(y ~ s(x) + (1 | id), data = dat)
```

And the summary is very similar.

```{r}
summary(mod)
```

However, the `plot` function now gives us a diagnostic plot, which looks very good. 

```{r}
plot(mod)
```

### Binomial Responses

In the cognition dataset, the responses relating to domain 2 and 3 are binomially distributed. We will use the first trial of the third domain to illustrate how such data can be modeled.

```{r}
dat <- subset(cognition, domain == 3 & item == 1)
```

Each observation counts the number of successes in ten trials.

```{r}
plot(dat$x, dat$y, xlab = "x", ylab = "Correct responses")
```

Again we can fit this model using gamm4.

```{r}
mod_gamm4 <- gamm4(cbind(y, trials - y) ~ s(x),
  random = ~ (1 | id),
  data = dat, family = binomial
)
```


```{r}
summary(mod_gamm4$mer)
```

```{r}
plot(mod_gamm4$gam)
```

The following code estimates the modeling using galamm instead.

```{r}
mod <- galamm(cbind(y, trials - y) ~ s(x) + (1 | id),
  data = dat, family = binomial
)
```

The estimates are very similar, although not identical. The difference in deviance is due to differences in the way deviance is defined. The call `deviance(mod_gamm4$mer)` gives the same value as in the summary for the model fitted with galamm.

```{r}
summary(mod)
```

## Generalized Additive Models with Factor Structures

We now add factor structures to the GAMMs. These are types of models that neither gamm4 nor mgcv are able to estimate, and where galamm provides new functionality.

### Gaussian Responses

We continue with the cognition data, but now use all items of cognitive domain 1. These are all conditionally normal distributed.

```{r}
dat <- subset(cognition, domain == 1)
dat$item <- factor(dat$item)
head(dat)
```

We now need a factor model to associate the underlying latent trait $\eta$ with the measurements $y_{i}$:

$$
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
$$

In the structural model, we have a smooth term for the relationship between the latent trait and x, and we have random intercepts for a given timepoint within subject $\zeta^{(2)}$, and for a given subject across timepoints $\zeta^{(3)}$.

$$
\eta = h(x) + \zeta^{(2)} + \zeta^{(3)}.
$$

The reduced form of the model is

$$
y_{i} = \beta_{i} + \lambda_{i} \left\{ h(x) + \zeta^{(2)} + \zeta^{(3)} \right\} + \epsilon_{i}
$$

We fit the model as follows.

```{r}
mod <- galamm(
  formula = y ~ 0 + item + s(x, by = loading) + (0 + loading | id / timepoint),
  data = dat,
  load.var = "item",
  lambda = list(matrix(c(1, NA, NA), ncol = 1)),
  factor = list("loading")
)
```

The factor loadings are very well recovered. When simulating the data, the standard deviation at the `id` level was 1, at the `timepoint` level it was 0.5, and the residual standard deviation was 0.1. The estimates are close to these values.

```{r}
summary(mod)
```

### Binomial Responses

We can now move on to the part of the cognition data that is conditionally binomially distributed. We begin with domain 2, for which each response measures success or not in is a single trial. In this case there are only two items, so we must change the lambda matrix accordingly.


```{r}
dat <- subset(cognition, domain == 2)
dat$item <- factor(dat$item)

mod <- galamm(
  formula = y ~ 0 + item + s(x, by = loading) + (0 + loading | id / timepoint),
  data = dat,
  family = binomial,
  load.var = "item",
  lambda = list(matrix(c(1, NA), ncol = 1)),
  factor = list("loading")
)
```

The factor loading $\lambda_{2} = 2$ was used when simulating the data, and including the uncertainty, our estimate covers the true value well.

```{r}
factor_loadings(mod)
confint(mod, "lambda")
```



# References
