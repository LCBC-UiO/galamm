---
title: "Semiparametric Latent Variable Modeling"
output:
  rmarkdown::html_vignette:
    fig_width: 6
    fig_height: 4
bibliography: ../inst/REFERENCES.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Semiparametric Latent Variable Modeling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE}
library(galamm)
library(gamm4)
library(ggplot2)
theme_set(theme_bw())
```

This vignette describes how to use galamm to estimate latent variable models with smooth terms. The examples are based on Section 4 and 5 in @sorensenLongitudinalModelingAgeDependent2023, but as we cannot share the data, we have instead simulated somewhat simpler datasets that will be used. We will gradually add complexity, starting with a simple generalized additive mixed.

## Generalized Additive Mixed Models

### Gaussian Responses

The `cognition` dataset contains simulated data with measurements of abilities in three cognitive domains.

```{r}
head(cognition)
```

For this first example, we focus only on the first item measured for the first domain.

```{r}
dat <- subset(cognition, domain == 1 & item == 1)
```

Each subject in this dataset has been measured eight times, and we can plot the measurements as follows:

```{r}
ggplot(dat, aes(x = x, y = y, group = id)) +
  geom_point(size = .1) +
  geom_line(alpha = .3)
```

We use a generalized additive mixed model with random intercepts per subject to estimate the function relating $x$ to $y$. In terms of the model framework outlined in the [introductory vignette](https://lcbc-uio.github.io/galamm/articles/galamm.html), we model the $i$th response from the $j$th subject with

$$
y_{ij} = f(x_{ij}) + \eta_{j} + \epsilon_{ij}
$$

where $f(x_{ij})$ is a smooth function to be estimated, $\eta_{j} \sim N(0, \psi)$ is a random intercept, and $\epsilon_{ij} \sim N(0, \phi)$ is a residual term.

This model can be estimated using gamm4 as follows:

```{r}
mod_gamm4 <- gamm4(y ~ s(x), random = ~ (1 | id), data = dat, REML = FALSE)
```

The resulting estimated smooth term looks sensible.

```{r}
summary(mod_gamm4$mer)
plot(mod_gamm4$gam)
```

With galamm we use similar argument, but the `random` specification is now part of the model formula.

```{r}
mod <- galamm(y ~ s(x) + (1 | id), data = dat)
```

And the summary is very similar.

```{r}
summary(mod)
```

However, the `plot` function now gives us a diagnostic plot, which looks very good. 

```{r}
plot(mod)
```

### Binomial Responses

In the cognition dataset, the responses relating to domain 2 and 3 are binomially distributed. We will use the first trial of the third domain to illustrate how such data can be modeled.

```{r}
dat <- subset(cognition, domain == 3 & item == 1)
```

Each observation counts the number of successes in ten trials.

```{r}
plot(dat$x, dat$y, xlab = "x", ylab = "Correct responses")
```

Again we can fit this model using gamm4.

```{r}
mod_gamm4 <- gamm4(cbind(y, trials - y) ~ s(x),
  random = ~ (1 | id),
  data = dat, family = binomial
)
```


```{r}
summary(mod_gamm4$mer)
```

```{r}
plot(mod_gamm4$gam)
```

Using galamm instead we do.

```{r}
mod <- galamm(cbind(y, trials - y) ~ s(x) + (1 | id),
  data = dat, family = binomial
)
```

The estimates are very similar, although not identical. The difference in deviance is due to differences in the way deviance is defined. The call `deviance(mod_gamm4$mer)` gives the same value as in the summary for the model fitted with galamm.

```{r}
summary(mod)
```


## Nonlinear Mixed Models with Factor Structures

To motivate the semiparametric estimation to follow, we start by looking at the items corresponding to domain 1 in the cognition data.

```{r}
ggplot(
  subset(cognition, domain == 1),
  aes(x = x, y = y)
) +
  geom_point(size = .5, alpha = .3) +
  geom_line(aes(group = id), linewidth = .4, alpha = .3) +
  facet_wrap(vars(item), labeller = as_labeller(function(x) paste("Item", x)))
```


It seem reasonable to assume that the underlying latent trait for domain 1 has a quadratic form. We hence estimate define the following measurement model

$$
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
$$

and the structural model

$$
\eta = \gamma_{1} x + \gamma_{2}x^{2} + \zeta^{(2)} + \zeta^{(3)}.
$$

where $\zeta^{(2)}$ is the random intercept within timepoint for a given subject, and $\zeta^{(3)}$ is the random intercept between timepoints within subject.

The reduced form of the model is

$$
y_{i} = \beta_{i} + \lambda_{i} \left\{\gamma_{1}x + \gamma_{2} x^{2} +  \zeta^{(2)} + \zeta^{(3)} \right\} + \epsilon_{i}
$$

We can fit this model using galamm as follows.

```{r}
dat <- subset(cognition, domain == 1)

mod <- galamm(
  formula = y ~ loading:(x + I(x^2)) + (0 + loading | id / timepoint),
  data = dat,
  load.var = "item",
  lambda = list(matrix(c(1, NA, NA), ncol = 1)),
  factor = list("loading")
)
```

The factor loadings are very close to the values used in when simulating the data, and both the linear and quadratic terms are clearly significant.

```{r}
summary(mod)
```


## Generalized Additive Models with Factor Structures

### Gaussian Responses

We now move on to semiparametric estimation. The measurement model is

$$
y_{i} = \beta_{i} + \lambda_{i} \eta + \epsilon_{i}
$$

and the structural model

$$
\eta = h(x) + \zeta^{(2)} + \zeta^{(3)}.
$$

The reduced form of the model is

$$
y_{i} = \beta_{i} + \lambda_{i} \left\{ h(x) + \zeta^{(2)} + \zeta^{(3)} \right\} + \epsilon_{i}
$$

We fit the model as follows.

```{r}
dat <- subset(cognition, domain == 1)
dat$item <- factor(dat$item)

mod <- galamm(
  formula = y ~ 0 + item + s(x, by = loading) + (0 + loading | id / timepoint),
  data = dat,
  load.var = "item",
  lambda = list(matrix(c(1, NA, NA), ncol = 1)),
  factor = list("loading")
)
```

The factor loadings are very well recovered. When simulating the data, the standard deviation at the `id` level was 1, at the `timepoint` level it was 0.5, and the residual standard deviation was 0.1. The estimates are close to these values.

```{r}
summary(mod)
```

### Binomial Responses

We can now move on to the part of the cognition data that is binomially distributed. We begin with domain 2, for which there is a single trial.





# References
