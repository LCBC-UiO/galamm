---
title: "Interactions Between Latent and Observed Variables"
output:
  rmarkdown::html_vignette:
    fig_width: 6
    fig_height: 4
bibliography: ../inst/REFERENCES.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Interactions Between Latent and Observed Variables}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---




```r
library(galamm)
```

This vignette describes how `galamm` can be used to model interactions between latent and observed variables. The models described here can be considered extensions of the covariate measurement error model described in the [vignette on mixed response types](https://lcbc-uio.github.io/galamm/articles/mixed_response.html#covariate-measurement-error-model), by allowing the latent variables to interaction with observed variables.

## Linear Mixed Model with Latent Covariates

For this example we use the simulated `latent_covariates` dataset, of which the first six rows are displayed below:


```r
head(latent_covariates)
#>   id         type         x          y response
#> 1  1 measurement1 0.8954758  0.7344445        0
#> 2  1 measurement2 0.8954758  0.8776636        0
#> 3  1     response 0.8954758  0.5012116        1
#> 4  2 measurement1 0.2871962 -1.6300863        0
#> 5  2 measurement2 0.2871962 -2.3726788        0
#> 6  2     response 0.2871962  0.6161934        1
```

### Model Formulation

The response variable `y` contains both measurements of a latent variable and measurements of the response that we actually are interested in modeling, and the `type` variable distinguishes these responses. In this case we have complete observations for each subject ID, and for a given ID, the measurement model can be written as follows:

$$
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3}
\end{pmatrix}
=
\boldsymbol{\beta}_{0} +
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & x
\end{pmatrix}
\begin{pmatrix}
1 \\
\lambda_{2} \\
\lambda_{3} \\
\lambda_{4}
\end{pmatrix}
\eta 
+
\begin{pmatrix}
0 \\
0 \\
x \beta
\end{pmatrix}
+ \boldsymbol{\epsilon}.
$$

In this equation $\boldsymbol{\beta}_{0} \in \mathbb{R}^{3}$ is a vector of intercepts, $\eta$ is a latent variable, the loading of the latent variable onto the first measurement $y_{1}$ is fixed to 1 for identifiability, $\lambda_{2}$ is the loading of the latent variable onto the second measurement $y_{2}$, $\lambda_{3}$ is the main effect of the latent variable on the response of interest $y_{3}$, $\beta$ is the effect of the observed covariate $x$ on $y_{3}$, and $\lambda_{4}$ is the interaction effect of $x$ and $\eta$ on $y_{3}$. We assume that the residuals $\boldsymbol{\epsilon}$ are independently and identically normally distributed; this assumption is valid in this simulated case, but note that since the response $y_{3}$ is qualitatively different from the measurements $y_{1}$ and $y_{2}$, this assumption will in general not hold, and a [heteroscedastic measurement model](https://lcbc-uio.github.io/galamm/articles/lmm_heteroscedastic.html) should be used, or a [model with mixed response types](https://lcbc-uio.github.io/galamm/articles/mixed_response.html). For a more detailed explanation of this way of formulating latent variable models in matrix form we refer to the first four pages of @rockwoodEstimatingComplexMeasurement2019.

The structural model is simply $\eta = \zeta \sim N(0, \psi)$, where $\psi$ is its variance.

### Model Without Interaction

It can be instructive to start by considering a model in which we fix $\\lambda_{4} = 0$. This type of model would be estimated with the following code:


```r
lambda <- list(matrix(c(1, NA, NA), ncol = 1))

mod0 <- galamm(
  formula = y ~ x:response + (0 + loading | id),
  data = latent_covariates,
  load.var = "type",
  lambda = lambda,
  factor = list("loading")
)
```

In the data generating simulations, the true values were $\lambda_{1}=1$, $\lambda_{2} = 1.3$ and $\lambda_{3} = -0.3$. The former two are very well recovered, but the latter is too positive, which is likely due to us omitting the interaction $\lambda_{4}$, whose true value was 0.2.


```r
summary(mod0)
#> GALAMM fit by maximum marginal likelihood.
#> Formula: y ~ x:response + (0 + loading | id)
#>    Data: latent_covariates
#> 
#>      AIC      BIC   logLik deviance df.resid 
#>    133.6    159.9    -60.8    121.6      594 
#> 
#> Scaled residuals: 
#>     Min      1Q  Median      3Q     Max 
#> -3.4256 -0.5231 -0.0151  0.4851  3.2519 
#> 
#> Lambda:
#>         loading       SE
#> lambda1  1.0000        .
#> lambda2  1.2915 0.012036
#> lambda3 -0.1952 0.007513
#> 
#> Random effects:
#>  Groups   Name    Variance Std.Dev.
#>  id       loading 1.05019  1.0248  
#>  Residual         0.01137  0.1066  
#> Number of obs: 600, groups:  id, 200
#> 
#> Fixed effects:
#>             Estimate Std. Error t value  Pr(>|t|)
#> (Intercept) -0.01275    0.01249  -1.021 3.073e-01
#> x:response   0.53475    0.02617  20.435 8.092e-93
```


### The Full Model

The measurement model can be equivalently written as

$$
\begin{pmatrix}
y_{1} \\
y_{2} \\
y_{3}
\end{pmatrix}
=
\boldsymbol{\beta}_{0} +
\begin{pmatrix}
1 \\
\lambda_{2} \\
\lambda_{3} + \lambda_{4} x
\end{pmatrix}
\eta 
+
\begin{pmatrix}
0 \\
0 \\
x \beta
\end{pmatrix}
+ \boldsymbol{\epsilon}.
$$

This way of writing shows more explicitly which factor loadings are connected with which observation. In order to fit this model with `galamm`, we must provide formulas for the terms in the loading matrix

$$
\begin{pmatrix}
1 \\
\lambda_{2} \\
\lambda_{3} + \lambda_{4} x
\end{pmatrix}.
$$

We specify the factor interactions with a list of lists. The reason for this notation is that we need one list to hold the regression terms for each loading variable specified in `load.var`.


```r
factor_interactions <- list(list(~ 1, ~ 1, ~ x))
```

This specifies that for the first two rows, there are no covariates, but for the third row, we want a linear regression with $x$ as covariate. Next, we specify the loading matrix **without** the interaction parameter, i.e., we reuse the `lambda` object that was specified for `mod0` above. This lets us fit the model as follows:


```r
mod <- galamm(
  formula = y ~ x:response + (0 + loading | id),
  data = latent_covariates,
  load.var = "type",
  lambda = lambda,
  factor = list("loading"),
  factor_interactions = factor_interactions
)
```

A model comparison shows overwhelming evidence in favor of this model, which is not surprising since this is how the data were simulated.


```r
anova(mod, mod0)
#> Data: latent_covariates
#> Models:
#> mod0: y ~ x:response + (0 + loading | id)
#> mod: y ~ x:response + (0 + loading | id)
#>      npar     AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
#> mod0    6 133.568 159.95 -60.784   59.173                         
#> mod     7  73.173 103.95 -29.587   59.173 62.395  1   2.81e-15 ***
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

The summary also shows that the bias in $\lambda_{3}$ has basically disappeared, as it is up to -0.291 from -0.195, with the true value being -0.3. The interaction is estimated at 0.197, which is also very close to the true value 0.2. It should of course be noted here that the noise level in this simulated dataset was set unrealistically low, to let us confirm that the implementation itself is correct.


```r
summary(mod)
#> GALAMM fit by maximum marginal likelihood.
#> Formula: y ~ x:response + (0 + loading | id)
#>    Data: latent_covariates
#> 
#>      AIC      BIC   logLik deviance df.resid 
#>     73.2    104.0    -29.6     59.2      593 
#> 
#> Scaled residuals: 
#>      Min       1Q   Median       3Q      Max 
#> -2.68699 -0.55501  0.01071  0.50135  2.98197 
#> 
#> Lambda:
#>           loading      SE
#> lambda1    1.0000       .
#> lambda2    1.2916 0.01113
#> lambda3   -0.2907 0.01366
#> lambda4_x  0.1970 0.02402
#> 
#> Random effects:
#>  Groups   Name    Variance Std.Dev.
#>  id       loading 1.05077  1.02507 
#>  Residual         0.00972  0.09859 
#> Number of obs: 600, groups:  id, 200
#> 
#> Fixed effects:
#>              Estimate Std. Error t value   Pr(>|t|)
#> (Intercept) -0.009083    0.01093 -0.8311  4.059e-01
#> x:response   0.526535    0.02281 23.0804 7.284e-118
```

We can also try to add interactions between the $x^{2}$ and $\eta$, as follows:


```r
factor_interactions <- list(list(~ 1, ~ 1, ~ x + I(x^2)))
```



```r
mod2 <- galamm(
  formula = y ~ x:response + (0 + loading | id),
  data = latent_covariates,
  load.var = "type",
  lambda = lambda,
  factor = list("loading"),
  factor_interactions = factor_interactions
)
```

Not as can be seen, the coefficient for this squared interaction is not significantly different from zero.


```r
summary(mod2)
#> GALAMM fit by maximum marginal likelihood.
#> Formula: y ~ x:response + (0 + loading | id)
#>    Data: latent_covariates
#> 
#>      AIC      BIC   logLik deviance df.resid 
#>     74.9    110.1    -29.4     58.9      592 
#> 
#> Scaled residuals: 
#>      Min       1Q   Median       3Q      Max 
#> -2.68511 -0.54763  0.00713  0.49697  2.98856 
#> 
#> Lambda:
#>                 loading      SE
#> lambda1         1.00000       .
#> lambda2         1.29158 0.01112
#> lambda3        -0.28302 0.01977
#> lambda4_x       0.14809 0.09475
#> lambda5_I(x^2)  0.05069 0.09503
#> 
#> Random effects:
#>  Groups   Name    Variance Std.Dev.
#>  id       loading 1.050763 1.02507 
#>  Residual         0.009713 0.09855 
#> Number of obs: 600, groups:  id, 200
#> 
#> Fixed effects:
#>              Estimate Std. Error t value   Pr(>|t|)
#> (Intercept) -0.009631    0.01097 -0.8783  3.798e-01
#> x:response   0.527492    0.02286 23.0724 8.773e-118
```


# References
